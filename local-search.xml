<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>小记_2023.5.24</title>
    <link href="/2023/05/24/%E5%B0%8F%E8%AE%B0-2023-5-24/"/>
    <url>/2023/05/24/%E5%B0%8F%E8%AE%B0-2023-5-24/</url>
    
    <content type="html"><![CDATA[<p> 为了更好的梳理思绪，规划自己的工作安排，打算开一个新系列，将头脑中的想法和要做的工作都记录一下，边梳理边规划，不然我实在分身乏力，难以为继，也省的我老是想一出是一出，导致很多想法没发落实到位，要放就尽早放，不要搞到一半了再放弃去做。该篇暂以小记为题。</p><p>&lt;--!more--&gt;</p><h1 id="小记">小记</h1><h2 id="最近学习计划">1.最近学习计划</h2><ol type="1"><li><p>毕业论文写作 6月6号答辩，今晚把格式整理好明天发给老师。如果没问题的话就第一次提交知网，也可以开始考虑准备答辩PPT了。</p></li><li><p>智习室的论文  这个一方面是任务，还有就是想法。</p></li></ol><p>任务是老师要求的那两篇文章，还是要再精细化的读一读。还有郭师兄的那个还要再进行一下政策梳理。</p><p>想法还有每次师兄师姐组会上分享的论文，听过了就过了，缺乏整理和思考，但。。。我感觉我实在是分不开了，要不就先等等吧。</p><ol start="3" type="1"><li>《蝶变四》阅读并整理</li></ol><p> 刚刚读完序章，了解了书的大致结构和内容。最近事情确实较多，有点静不下心来去读书，就暂定答辩之前完成阅读和整理吧。</p><ol start="4" type="1"><li>《深度学习》阅读并整理</li></ol><p> 这本现在是进行到第四章的计算机视觉，这两天都没动。一方面是事情多，另一方面是确实对是否要往下进行产生了质疑。 产生质疑的主要愿意有：第一，AIGC的发展使得我产生了疑问：个人的深度学习训练有意义吗？第二，就是关于我的研究方向，之后还是会朝着管理方向去进行，就算涉及人工智能，也无需去探求技术细节。 我尽可能的给自己理由去说服自己：首先，AIGC发展是基于深度学习的，我现在对深度学习的理解还很浅显，没办法帮助我直接过渡到AIGC的一系列模型。其次，即便现在大模型发展初现成果，但学习深度学习的基本理论依旧是有用的，而且我暂时也不打算从技术方面入手去写论文，个人现在难以去做这方面的突破与我也没什么关系呀。当然还有最关键的一点，我还是希望对这本书的阅读能够有始有终。 综上，继续阅读！干起来！</p><p align="right">lucky</p><p align="right">时2023年5月24日</p>]]></content>
    
    
    <categories>
      
      <category>小记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>小记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习Part1</title>
    <link href="/2023/05/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Part1/"/>
    <url>/2023/05/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Part1/</url>
    
    <content type="html"><![CDATA[<h1 id="part1">Part1</h1><p>由于希望能够更多的记下重点的和自己不是很熟悉的知识点，本书不按照书中的章节而按照每次的整理进行记录</p><h2 id="a-first-look-at-a-neural-network">A first look at a neuralnetwork</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">from</span> tensorflow.keras.datasets import mnist<br><span class="hljs-keyword">from</span> tensorflow import keras<br><span class="hljs-keyword">from</span> tensorflow.keras import layers<br><br>(train_images, train_labels), (test_images, test_labels) = mnist.load_data()  # Loading the MNIST datasets <span class="hljs-keyword">in</span> Keras<br><br>model = keras.Sequential([<br>    layers.Dense(512, <span class="hljs-attribute">activation</span>=<span class="hljs-string">&quot;relu&quot;</span>),<br>    layers.Dense(10, <span class="hljs-attribute">activation</span>=<span class="hljs-string">&quot;softmax&quot;</span>)<br>])  # The<span class="hljs-built_in"> network </span>architectrue<br><br>model.compile(<span class="hljs-attribute">optimizer</span>=<span class="hljs-string">&quot;rmsprop&quot;</span>,<br>            <span class="hljs-attribute">loss</span>=<span class="hljs-string">&quot;sparse_categorical_crossentropy&quot;</span>,<br>            metrics=[<span class="hljs-string">&quot;accuracy&quot;</span>])  # The compliation <span class="hljs-keyword">step</span><br><br><br><span class="hljs-comment"># preparing the image data</span><br>train_images = train_images.reshape((60000, 28<span class="hljs-number">*28</span>))<br>train_images = train_images.astype(<span class="hljs-string">&quot;float32&quot;</span>)/255<br>test_images = test_images.reshape((10000, 28 * 28))<br>test_images = test_images.astype(<span class="hljs-string">&quot;float32&quot;</span>) / 255<br><br><span class="hljs-comment"># Fitting the model</span><br>model.fit(train_images, train_labels, <span class="hljs-attribute">epochs</span>=5, <span class="hljs-attribute">batch_size</span>=128)<br><br><span class="hljs-comment"># Using the model to make predictions</span><br>test_digits = test_images[0:10]<br>predictions = model.predict(test_digits)<br><br>predictions[0].argmax()  # 预测结果<br><br><span class="hljs-comment"># Evaluating the model on new data</span><br>test_loss, test_acc = model.evaluate(test_images, test_labels)<br><span class="hljs-builtin-name">print</span>(f<span class="hljs-string">&quot;test_acc:&quot;</span>&#123;test_acc&#125;)<br><br></code></pre></td></tr></table></figure><p>  上面实现了一个简单的神经网络，下面简单对神经网络的工作原理进行解释。</p><h3 id="神经网络中的层">1.神经网络中的层</h3><p>神经网络中每层对输入数据所做的操作保存在<strong>权重(weights)</strong>中。用术语来说，每层实现的变换由其权重“参数化(parameterize)”，权重有时也被成为参数。<strong>学习</strong>的意思就是为神经网络中的每一个层找到一组权重值，使得该网络能够将每个示例输入与其目标正确地一一对应。</p><p>在上例中，通过叠加Dense层来构建网络</p><p><code>keras.layers.Dense(512, activation="relu")</code></p><p>该层可以理解为这样一个函数</p><p><code>output = relu(dot(W, input) + b)</code>其中relu()为非线性变换，而中间的函数为一个先✖️再+的线性变换。</p><p>以下为其实现 <figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sas">def naive_relu(<span class="hljs-meta">x</span>):<br>    assert l<span class="hljs-meta">en(</span><span class="hljs-meta">x</span>.shape) == 2<br>    <br>    <span class="hljs-meta">x</span> = <span class="hljs-meta">x</span>.copy()<br>    for i <span class="hljs-meta">in</span><span class="hljs-meta"> range(</span>l<span class="hljs-meta">en(</span><span class="hljs-meta">x</span>.shape[0])):<br>        for j <span class="hljs-meta">in</span><span class="hljs-meta"> range(</span>l<span class="hljs-meta">en(</span><span class="hljs-meta">x</span>.shape[1])):<br>            <span class="hljs-meta">x</span>[i][j] =<span class="hljs-meta"> max(</span><span class="hljs-meta">x</span>[i][j], 0)<br>    <span class="hljs-meta">return</span> <span class="hljs-meta">x</span><br><br></code></pre></td></tr></table></figure> 在numpy中可以直接进行逐元素计算</p><p><code>z = x + y   # 逐元素相加</code><code>z = np.maximum(z, 0.)  # 逐元素relu</code></p><p>不同的数据类型需要不同的层去处理</p><ul><li><p>向量数据(samples, features)为2D张量，通常用密集连接层(denselyconnected layer)，也叫全连接层(fully connected layer)或密集层(denselayer)，对应keras中的Dense类。</p></li><li><p>序列数据(samples, timesteps,features)为3D张量，通常用循环层(recurrentlayer),比如keras中的LSTM层来处理。</p></li><li><p>图像数据保存在4D张量中，通常用二维卷积层，例如Keras中的Conv2D处理。</p></li></ul><h3 id="模型层构成的网络">2.模型：层构成的网络</h3><p>  深度学习模型是层构成的有向无环图。</p><p>选定了网络拓扑结构，意味着将<strong>可能性空间(假设空间)</strong>限定一系列张量运算。</p><h3 id="损失函数与优化器配置学习的关键">3.损失函数与优化器:配置学习的关键</h3><ul><li><p>损失函数:在训练过程中需要将其最小化，它能够衡量当前任务是否完成。</p></li><li><p>决定如何基于损失函数对网络进行更新。它执行的是随机梯度下降(SGD)的某个变体。</p></li></ul><p>  具有多个输出的神经网络可能具有多个损失函数(每个输出对应一个损失函数)。但是，梯度下降过程必须基于<strong>单个</strong>标量损失值，因此，对于具有多个损失函数的网路，需要将所有损失函数取平均，变为一个标量值。</p><h4 id="反向传播">反向传播</h4><p>实际上就是利用链式法则进行求导。 Show the code.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs stylus">W = tf<span class="hljs-selector-class">.Variable</span>(tf<span class="hljs-selector-class">.random</span><span class="hljs-selector-class">.uniform</span>((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)))<br><span class="hljs-selector-tag">b</span> = <span class="hljs-selector-tag">tr</span><span class="hljs-selector-class">.Variable</span>(tf<span class="hljs-selector-class">.zeros</span>((<span class="hljs-number">2</span>,)))<br>x = <span class="hljs-selector-tag">tr</span><span class="hljs-selector-class">.random</span><span class="hljs-selector-class">.uniform</span>((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>))<br><br>with tf<span class="hljs-selector-class">.GradientTape</span>() as tape:<br>    y = tf<span class="hljs-selector-class">.matmul</span>(x, W) + <span class="hljs-selector-tag">b</span><br><br>grad_of_y_wrt_W_and_b = tape<span class="hljs-selector-class">.gradient</span>(y, <span class="hljs-selector-attr">[W, b]</span>)<br></code></pre></td></tr></table></figure><h1 id="reimplementing-our-first-example-from-scrach-in-tensorflow">Reimplementingour first example from scrach in Tensorflow</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># A simple Dense class</span><br><br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NaiveDense</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, inputsize, outputsize, activation</span>):</span><br>        self.activation = activation  <br><br>        w_shape = (inputsize, outputsize)<br>        w_initial_value = tf.random.uniform(w_shape, minval=<span class="hljs-number">0</span>, maxval=<span class="hljs-number">1e-1</span>)<br>        self.W = tf.Variable(w_initial_value)<br><br>        b_shape = (outputsize,)<br>        b_initial_value = tf.zeros(b_shape)<br>        self.b = tf.Variable(b_initial_value)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__call__</span>(<span class="hljs-params">self, inputs</span>):</span><br>        <span class="hljs-keyword">return</span> self.activation(tf.matmul(inputs, self.W) + self.b)<br>    <br><span class="hljs-meta">    @property</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">weights</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">return</span> [self.W, self.b]<br><br><span class="hljs-comment"># A simple Sequential class</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NaiveSequential</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, layers</span>):</span><br>        self.layers = layers<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__call__</span>(<span class="hljs-params">self, inputs</span>):</span><br>        x = inputs<br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> layers:<br>            x = layer(x)<br>        <span class="hljs-keyword">return</span> x<br>    <br><span class="hljs-meta">    @property</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">weights</span>(<span class="hljs-params">self</span>):</span><br>        weights = []<br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> layers:<br>            weights += layer.weights<br>        <span class="hljs-keyword">return</span> weights<br><br><br><span class="hljs-comment"># the network structure</span><br><br>model = NaiveSequential([<br>    NaiveDense(inputsize=<span class="hljs-number">28</span>*<span class="hljs-number">28</span>, outputsize=<span class="hljs-number">512</span>, activation=tf.nn.relu),<br>    NaiveDense(inputsize=<span class="hljs-number">512</span>, outputsize=<span class="hljs-number">10</span>, activation=tf.nn.softmax)<br>])<br><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(model.weights) == <span class="hljs-number">4</span><br><br><span class="hljs-comment"># A batch generator</span><br><br><span class="hljs-keyword">import</span> math<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BatchGenerator</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, images, labels, batch_size=<span class="hljs-number">128</span></span>):</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(images) == <span class="hljs-built_in">len</span>(labels)<br>        self.index = <span class="hljs-number">0</span><br>        self.images = images<br>        self.labels = labels<br>        self.batch_size = batch_size<br>        self.num_batchs = math.ceil(<span class="hljs-built_in">len</span>(iamges)/batch_size)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">next</span>(<span class="hljs-params">self</span>):</span><br>        images = self.images[self.index : self.index + self.batch_size]<br>        labels = self.labels[self.index: self.index + self.batch_size]<br>        self.index += self.batch_size<br>        <br>        <span class="hljs-keyword">return</span> images, labels<br><br><br>learning_rate = <span class="hljs-number">1e-3</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update_weights</span>(<span class="hljs-params">gradients, weights</span>):</span><br>    <span class="hljs-keyword">for</span> g, w <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(gradients, weights):<br>        w.assign_sub(g * learning_rate)<br><br><br><span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> optimizers<br><br>optimizer = optimizers.legacy.SGD(learning_rate=<span class="hljs-number">1e-3</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update_weights</span>(<span class="hljs-params">gradients, weights</span>):</span><br>    optimizer.apply_gradient(<span class="hljs-built_in">zip</span>(gradient, weights))<br><br><br><span class="hljs-comment"># Running a training step</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">one_training_step</span>(<span class="hljs-params">model, images_batch, labels_batch</span>):</span><br>    <span class="hljs-keyword">with</span> tf.GradientTape() <span class="hljs-keyword">as</span> tape:<br>        preditions = model(images_batch)<br><br>        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(label_batch, predictions)  <span class="hljs-comment"># 损失函数根据具体情况做出调整</span><br><br>        average_loss = tf.reduce_mean(per_sample_losses)<br>    gradients = tape.gradient(average_loss, model.weights)<br>    update_weights(gradients, model.weights)<br><br>    <span class="hljs-keyword">return</span> average_loss<br><br><br><span class="hljs-comment"># The full training loop</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">model, images, labels, epochs, batch_size=<span class="hljs-number">128</span></span>):</span><br>    <span class="hljs-keyword">for</span> epoch_counter <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;epoch:<span class="hljs-subst">&#123;epoch_counter&#125;</span>&quot;</span>)<br>        batch_generator = BatchGenerator(images, labels)<br><br>        <span class="hljs-keyword">for</span> batch_counter <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_generator.num_batches):<br>            images_batch, labels_batch = batch_generator.<span class="hljs-built_in">next</span>()<br>            loss = one_training_step(model, images_batch, labels_batch)<br><br>            <span class="hljs-keyword">if</span> batch_counter % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;loss at batch <span class="hljs-subst">&#123;batch_counter&#125;</span>:<span class="hljs-subst">&#123;loss:<span class="hljs-number">.2</span>f&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 进行训练</span><br>(train_images, train_labels), (test_images, test_labels) = mnist.load_data()<br><br>train_images = train_images.reshape((<span class="hljs-number">60000</span>, <span class="hljs-number">28</span> * <span class="hljs-number">28</span>))<br>train_images = train_images.astype(<span class="hljs-string">&quot;float32&quot;</span>) / <span class="hljs-number">255</span><br>test_images = test_images.reshape((<span class="hljs-number">10000</span>, <span class="hljs-number">28</span> * <span class="hljs-number">28</span>))<br>test_images = test_images.astype(<span class="hljs-string">&quot;float32&quot;</span>) / <span class="hljs-number">255</span><br><br>fit(model, train_images, train_labels, epochs=<span class="hljs-number">10</span>, batch_size=<span class="hljs-number">128</span>)<br><br><span class="hljs-comment"># Evaluting the model</span><br><br>preditions = model(test_images).numpy()<br>predicted_labels = np.argmax(predictions, axis=<span class="hljs-number">1</span>)<br>matches = predicted_labels == test_labels<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;accuracy:<span class="hljs-subst">&#123;matches.mean():<span class="hljs-number">.2</span>f&#125;</span>&quot;</span>)<br><br></code></pre></td></tr></table></figure><p>这一段手动实现神经网络很有学习价值，多看几遍，重点在梯度更新那里。</p><p align="right">lucky</p><p align="right">时2023年5月21日</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习</title>
    <link href="/2023/05/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/05/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>  接下来，将会开始阅读《Deeplearning withpython》，并进行整理归纳，总结感悟。 <span id="more"></span></p><p>主要针对关键概念和代码进行整理，一方面为了回顾和查阅知识点，方便复制代码；另一方面是训练代码能力。</p><p>当前为5月21日，最近马上毕业，还有答辩等事情，还是尽量把时间排的开一点。全书共九章，因为本身有一定基础，前五章一周完成整理，即到5月28日前完成前五章，后面四章暂定每周两章进行整理。</p><p align="right">lucky</p><p align="right">时2023年5月21日</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>蝶变三_终章</title>
    <link href="/2023/05/21/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%BB%88%E7%AB%A0/"/>
    <url>/2023/05/21/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%BB%88%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>接下来，将会开始阅读杨老师的《蝶变》系列，并进行整理归纳，总结感悟。</p><p>该篇为蝶变三的终章 <span id="more"></span></p><h1 id="终章">终章</h1><p>  在前面的章节中探讨了如何打造企业的智能引擎实现商业进化：从三体引擎的创建、认知并向未来进行“转场”、如何使用重联来点火发动、如何用“智算代劳”的方式驾驶企业之车、如何穿行于“数实共生”的街道以及最后的马赛克化的组织解耦的实现。这些内容有一个核心贯穿始终——数据，文中这些过程都是数据及其相关思想所引发的在企业方面的改变，更加全面的剖析了如何让数据为企业发展赋能，既有实际的案例，也有面向未来的启蒙。</p><p>  在文章的最后也提出，这本书不是一份“路线图”，而是思考未来之路的一个催化剂。</p><p align="right">lucky</p><p align="right">时2023年5月21日</p>]]></content>
    
    
    <categories>
      
      <category>蝶变三</category>
      
    </categories>
    
    
    <tags>
      
      <tag>蝶变</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>蝶变三_第六章</title>
    <link href="/2023/05/21/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E5%85%AD%E7%AB%A0/"/>
    <url>/2023/05/21/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E5%85%AD%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>接下来，将会开始阅读杨老师的《蝶变》系列，并进行整理归纳，总结感悟。</p><p>该篇为蝶变三的第六章 <span id="more"></span></p><h1 id="马赛克化">马赛克化</h1><p>  感觉这一章更多的是具体的来谈上一章中提到的管理问题解决路径的第二条，即管理上收，责任下沉的具体实现。</p><p>  在本章中更加详细的描述了这一过程并将其命名为企赛克，介绍了三个企业的解决方案提供参考：包括海尔的去海尔化，字节跳动的context管理，华为的分布式协同。它们都实现了不同程度上的“弱中心化”，激发了企业活力。</p><p>  文章的最后介绍了分布式自治组织(Distributed Autonomous Organization,DAO)，介绍了它相比于传统架构的优势，也提到了在实践过程中遇到的一些障碍，这种新型的企业架构目前还是一种启蒙。</p><p align="right">lucky</p><p align="right">时2023年5月21日</p>]]></content>
    
    
    <categories>
      
      <category>蝶变三</category>
      
    </categories>
    
    
    <tags>
      
      <tag>蝶变</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>蝶变三_第五章</title>
    <link href="/2023/05/18/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E4%BA%94%E7%AB%A0/"/>
    <url>/2023/05/18/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E4%BA%94%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>接下来，将会开始阅读杨老师的《蝶变》系列，并进行整理归纳，总结感悟。</p><p>该篇为蝶变三的第五章 <span id="more"></span></p><h1 id="数实共生">5.数实共生</h1><p>这一章围绕企业自身去进行探讨，总体是引出问题，提出解决方案，面向未来的结构。</p><h2 id="企业困境">5.1 企业困境</h2><p>  第一部分从本源出发探讨企业为什么会面临困境。引用著名经济学家、诺贝尔奖获得者罗纳德·科斯(RonaldH.Coase)的观点：当市场交易成本高于组织的管理成本时，企业就诞生了。并进一步的得出了两个结论：企业之所以会存在，是因为可以节约市场交易成本；当企业内部的管理成本高于可以节约的市场交易成本时，企业就没有存在的价值了。</p><p>  这就引到了第二部分，并接上了前面的章节：在社会数字化、智能化的过程中，链接大量增多重塑了诸多关系，并且由于其无形易传播的特性，极大降低了市场上的交易成本，这才是问题的来源；另一方面，企业内部的员工同样作为社会网络中的一员，同样可能会在一定程度上脱离组织，即人可能在组织中，但心却不在了。（思考：这个问题之前也提到过，前几章提的是客户开始参与进组织的内部活动中，二者结合可以得出这样一个结论：在数字化、智能化的冲击下，企业等组织所定义的各种边界开始开始被信息渗入并模糊化）。总结当今企业管理面临的两大挑战：更加有效率的市场和“精神叛逃”的员工。</p><h2 id="管理重生">5.2 管理重生</h2><p>首先指出了传统业态经营者的焦虑，并指出了数字化时代的商业进化的核心思想：建立数字思维，并给出了两条切实可行的实现路径。</p><p>路径一：用更少的人去做到更多的事情。</p><p>  引用了迈克尔·波特(MichaelPorter)的价值链理论：企业最终的绩效是由一系列相互关联的价值创造环节构成的，所以企业可以识别价值贡献较小的环节，并将其“外包”出去，完成企业内部事项的社会化。</p><p>路径二：管理上收，责任下沉</p><p>  按我的理解，是要将企业转化为生态或者说是一个平台，平台上的人不再是传统意义上的“打工人”，而是价值的创造者，他们在这个生态中不仅进行企业整体的价值创造，也创造自身价值。</p><p>  书中描述：员东(员工+股东)不再是打工者，而是生态家园的守护者，是价值观的共鸣者，是价值交换的促发者，是生态逻辑的坚守者，也是生态进化的主导者，他们自由而又充满创造力！表达了作者对未来生态热烈而美好的期望。</p><h2 id="智能与共">5.3 智能与共</h2><p>  提出了一个非常重要的观点：智能技术替代的并不是企业内部的员工，而是岗位胜任力。人工智能与员工之间的关系并非单纯的替代，反而存在大量合作共生的可能性。</p><p>  最后作者指出，无论是哪种情况，智能系统的引入都会提升企业的整体效益，只是提升的幅度有所差异，表明随着时间的流逝，智能系统一定会以各种方式渗透进企业组织的内部，成为驱动绩效成长的一种关键力量。</p><p align="right">lucky</p><p align="right">时2023年5月18日</p>]]></content>
    
    
    <categories>
      
      <category>蝶变三</category>
      
    </categories>
    
    
    <tags>
      
      <tag>蝶变</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>蝶变三_第四章</title>
    <link href="/2023/05/16/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E5%9B%9B%E7%AB%A0/"/>
    <url>/2023/05/16/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E5%9B%9B%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>接下来，将会开始阅读杨老师的《蝶变》系列，并进行整理归纳，总结感悟。</p><p>该篇为蝶变三的第四章 <span id="more"></span></p><h1 id="智算代劳">4.智算代劳</h1><p>  该章主要讲述数据或者说是人工智能开始代替传统方式的优势。首先通过将实物进行数据表征和数据透视，这种透视或表征一旦完成，就会形成具体实在的一个虚拟表示，这种虚拟表示能够在一定程度上代替实物进行关系链接，就有可能造成上一章所描述的关系重塑，这也是引起传统架构重塑的重要导火线。在本章中，作者还指出这也会导致实物原本的价值被放大。</p><p>  从营销角度看这越来越指向单一的或者小众的客户，在传统营销无法顾及他们的情况下，数字化技术改变了这一现状，实现了营销数值的进一步增长，也就是所谓的长尾效应(longtail)。</p><p>作者指出人工智能开始替代人类的原因：它们有“人工不能”的能。</p><ol type="1"><li>人工不能不休息。</li><li>人不能一直保持头脑清醒</li><li>人不能客服贪欲</li><li>人不能没有感情</li><li>人不能没有享乐</li><li>人不能复制人</li><li>人不能离开人</li></ol><p>而人工智能恰能弥补这些缺点，在这些方面它们替代人类也就成了必然的趋势。</p><p>  在这里作者也清晰的给了人工智能一个定位：让人工智能在我们不能做到的地方做的更好！这指出了人工智能在人类发展过程中的辅助作用，也表明没有人类就没有人工智能，人工智能应当是人类进行价值创造的辅助工具或是助手。</p><p align="right">lucky</p><p align="right">时2023年5月16日</p>]]></content>
    
    
    <categories>
      
      <category>蝶变三</category>
      
    </categories>
    
    
    <tags>
      
      <tag>蝶变</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>蝶变三_第三章</title>
    <link href="/2023/05/15/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E4%B8%89%E7%AB%A0/"/>
    <url>/2023/05/15/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E4%B8%89%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>接下来，将会开始阅读杨老师的《蝶变》系列，并进行整理归纳，总结感悟。</p><p>该篇为蝶变三的第三章 <span id="more"></span></p><h1 id="关系重联">3.关系重联</h1><p>在有了互联网后，越来越多的事物和信息被链接起来，正是这种链接在重塑原本的关系，新时代背景下商业进化的逻辑也由此开始。</p><h2 id="链接的威力">3.1 链接的威力</h2><p>该段主要是举了多个行业的实例来展现链接所带来的关系重塑对企业的影响之大。</p><h3 id="出版行业">3.1.1 出版行业</h3><p>传统的出版行业的关键角色主要包括作者、出版社、印刷厂、经销商、零售商和读者，他们之间的连接本来是序贯的，但现在随着互联网的不断发展，读者可以通过与其他各部分甚至在读者之间进行链接，这完全破坏了原本的传统架构，引发了各种各样的问题，每一个关键角色都面临着新的挑战。</p><p>这同样的展现了一个趋势：读者或者说是客户在整个体系中正在扮演着越来越重要的角色，逐渐成为引导变革的主体。可能是由于链接打破传统架构迫使其他各关键角色朝着客户期望的方向前进，顾客在这个过程中逐渐取得了主导权。</p><h3 id="教育行业">3.1.2 教育行业</h3><p>教育行业的重联主要体现在摆脱了学校这一固定地点，让学生与包括老师在内的教育资源直接重联。一系列的举措也在被实施以帮助还原线下的场景以及学位证明。</p><h3 id="医疗行业">3.1.3 医疗行业</h3><p>医疗行业的重联同样体现在摆脱地点的束缚，同时也在一定程度上改变了医患之间的信息不对称问题，重塑了医生与病患的关系，同时医典和药典的数据化也重塑了医生与医生之间的关系。</p><h3 id="制造行业">3.1.4 制造行业</h3><p>小米使用户参与到了产品从生产到销售的全流程，在传统的链接之中加入了一条“用户参与线”。湘潭钢厂进行了工人与设备的重联，更多的以数字化的方式进行生产及管理。</p><h2 id="重联蝶变">3.2 重联蝶变</h2><p>该段提出这种重联指的不一定是数字化，但一定是商业元素的重新构建。该段以集美家居广场为例，阐述了集美面对数字化冲击的种种问题，开始改变思路，进行商业元素的重联。让现有的商业元素对接客户需求，完成面向未来的重联。</p><p>从本章的叙述中可以看到商业进化的几种趋势：序贯式的或者说是一种线性的架构正在被打破，各关键角色的相互关系开始呈现网络化的趋势；客户正在扮演着越来越重要的地位，甚至开始融合进企业，成为生产的一员；商业运行的过程正在变得越来越数字化，在本段中表现为生产的数字化和摆脱地点的限制，除此之外一定还有许多特征。这几种趋势同样也可看作是进行商业元素重联的特点或者说产生的结果。</p><p align="right">lucky</p><p align="right">时2023年5月15日</p>]]></content>
    
    
    <categories>
      
      <category>蝶变三</category>
      
    </categories>
    
    
    <tags>
      
      <tag>蝶变</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>蝶变三_第二章</title>
    <link href="/2023/05/14/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E4%BA%8C%E7%AB%A0/"/>
    <url>/2023/05/14/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E4%BA%8C%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>接下来，将会开始阅读杨老师的《蝶变》系列，并进行整理归纳，总结感悟。</p><p>该篇为蝶变三的第二章，考虑到时间问题，从这章开始内容上会更加简略一些，尽可能的把文章想要表达的思想和自己的见解加上即可。<span id="more"></span></p><h1 id="思维转场">2. 思维转场</h1><p>本章着重强调：随着人工智能的发展，人类面临着新一轮的以数据为基础的转场。在新的转场中，产品、客户和员工组成的经营三体不会改变，但它们会在新的场景下演绎出更加精彩的故事。该章节主要探讨的就是他们的相互关系。</p><h2 id="品客">2.1 品客</h2><p>文章提出过去的从产品入手和从客户入手的视角都承认了产品和客户之间的距离，但未来随着数据技术的不断发展，这种距离会变得越来越小。在未来，所有的营销人员都会成为数据工作者(或者说未来的数据工作者许多都会学习营销理论)，每个人都有可能成为“产销合一者”(pro-sumer)，产品不再是由他者生产出来的，而是个体需要的自然表达。</p><h2 id="品员">2.2 品员</h2><p>该段以大骨头公司为例，描述了该公司发展遇到的员工生产方面的问题，以及现代化的3D打印技术对该公司品员关系的重塑。一方面是生产工人开始退出生产舞台，另一方面设计产品图纸的人进入生产系统。思考：这种工坊式的生产方式与零工经济有怎样的关系呢？</p><h2 id="客员">2.3 客员</h2><p>该段从以下几个方面阐述了客员关系的变化</p><ol type="1"><li>关系距离在缩短</li><li>关系持续密切</li><li>客户反向管理员工</li><li>客户反向帮助员工</li><li>数字技术大幅扩展了员工与客户联系的范围和规模</li></ol><p>总而言之，在市场不确定性增强的情况下，员工与客户之间的距离越来越短，两者之间的互动越来越持续，互动的内容和范围开始超出产品和头部市场，从而呼唤全新的管理和运营思想。</p><p align="right">lukcy</p><p align="right">时2023年5月14日</p>]]></content>
    
    
    <categories>
      
      <category>蝶变三</category>
      
    </categories>
    
    
    <tags>
      
      <tag>蝶变</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>蝶变三_第一章</title>
    <link href="/2023/05/13/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E4%B8%80%E7%AB%A0/"/>
    <url>/2023/05/13/%E8%9D%B6%E5%8F%98%E4%B8%89-%E7%AC%AC%E4%B8%80%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>接下来，将会开始阅读杨老师的《蝶变》系列，并进行整理归纳，总结感悟。</p><p>该篇为蝶变三的第一章 <span id="more"></span></p><h1 id="经营三体">1.经营三体</h1><p>  在一开头就指出了企业经营过程中绩效的重要性，并指出根据熊彼特的创新理论，企业家精神就体现在对生产函数的转变上，不同的企业家拥有同样的投入会带来不同的产出，其差异的原因就在于不同组织投入的组合方式不同，以及转换函数不一样。</p><h2 id="大头针实验">1.1 大头针实验</h2><p>  对大头针工厂实验的考察经历了这样一个过程：由考察大头针工厂的内部生产方式，到生产与市场的会话，最后有回归到工厂内部。通过不断的追问，老师让我们清楚的看到了这样一个组织进行绩效创造的事实，即一家企业所做的全部事情，无非是把员工组织起来投入生产资料生产出产品并销售给客户。这当中，产品、客户和员工构成了经营的三要素。通过每一个要素，我们都可以直达经营业绩（收入）的路径：产品价格与产品销量的乘积等于收入、客户数量与客单价的乘积等于收入、员工数量与平均人效的乘积也等于收入。如果把经营业绩比作山峰的话，那么以上就是三条登山路径。老师将产品、客户和员工三要素比作“经营三体”，借此说明企业经营过程中的牵一发而动全身。</p><p>  从不同的路径来看目标，这种登山路径的探寻方法能够提供多种不同的视角，实现探寻多种实现路径。</p><h2 id="产品">1.2 产品</h2><p>这部分中，阐释了产品的多层含义。</p><ol type="1"><li>是需求在召唤产品，而不是客户</li></ol><p>   营销工作的目的就是将客户欲望引起的需求引导到具体的商品上来。</p><ol start="2" type="1"><li>产品只是满足客户需求的一种手段，而不是唯一的手段。</li></ol><p>   我们在看待产品的时候一定要避免“产品近视症”，不要只将眼光局限在产品竞争或同行业的竞争，很多竞争具有跨领域跨维度的特点。</p><ol start="3" type="1"><li>产品可以有多种形态。</li></ol><p>   任何一个产品都是处在有形与无形的中间形态，有形与无形的精准调校是进行产品创新的利器。</p><ol start="4" type="1"><li>产品不是孤立的，其价值实现是多层次的。</li></ol><p>   一般来说，产品在客户眼里的价值包含三个层次：产品本身的功能(F)、配套设施的丰富性(U)、用户基数(B)，三者相合就是产品在客户眼中的综合价值。</p><ol start="5" type="1"><li>产品是有生命周期的。</li></ol><p>   一项产品一般会经历导入、增长、成熟、衰退四个阶段。企业面对产品的生命周期，一部分会选择顺其自然，另一部分会致力于改变产品所处的周期阶段。</p><ol start="6" type="1"><li>产品，尤其是数字化产品，通常会产生网络外部性(networkexternality)。</li></ol><p>   网络外部性通俗来讲就是富者愈富、穷者愈穷的马太效应。产品的实际渗透方式通常是不以线性增长展开，但我们的产品规划思维基本上都是线性的。</p><p>在这部分阐述的不但是产品的多层含义，也是审视产品的多个视角。</p><h2 id="客户">1.3 客户</h2><p>  书中提出，针对客户的研究主要分为三个阶段。用了三个很形象的词进行描述，分别是“归堆儿”、“扎针儿”和“找人儿”。其中前两个都是关注于客户个人，分别从空间和时间上获利，而最后的“找人儿”则关注于客户构建的社会网络。下面将重点对书中的几个阶段进行总结。</p><h3 id="扎堆儿">1.3.1 扎堆儿</h3><p>  也就是通常所说的"STP战略",主要包括市场细分（Segmenting）、目标市场选择(Targeting)和目标市场定位(Positioning)。该法存在着一个基本假定：细分市场内部的客户需求是完全同质的，而细分市场之间的客户需求是完全异质的。这是一种针对同质需求实行无差异营销的销售策略，是一种在空间上的或者说是一种“面儿”上的划分，就好像切蛋糕，研究的是如何下刀，切成几块的问题。但这也是该方法可能产生问题的来源：企业面对市场不断的进行更加精细的细分以期增强销售效果，但却很容易会造成一种“细分不成反被分”的局面，因为用户的需求是多样且复杂的，有时可能一个客户被归到的许多的细分市场之中，蛋糕没法切了，因此归堆法可以当做一种“商品范式”(productparadigm)，简化表达为One 2 All。</p><h3 id="扎针儿">1.3.2 扎针儿</h3><p>  相比于扎堆儿“面儿”上的切分，扎针儿法打破了STP的同质性的假定，将客户看做是发展变化的，是一种时间的逻辑。它要确保两件事情：第一是要尽可能的维系住客户，第二是要想方设法的让客户在每个阶段都多买你的东西，也叫增加客户钱包份额。</p><p>  维系客户的常用方法是尽可能的创造客户满意，引起重复购买、推荐购买和口碑传播，当然客户满意也未必就真的愿意购买，“召唤产品的是需求，而不是客户”，而且客户也是喜新厌旧的。另一方面很多时候客户愿意进行购买也可能是因为供应限制或外部压力。</p><p>  要提高客户的钱包份额，书中主要提到三种策略：一是提高采购量，二是增加采购品种，一方面是增加采购品种，另一方面是构建品牌联盟以增加交叉销售(crossselling)。三是客户策反，想将竞争对手已经培养起来的高价值用户移植到自己这里。</p><p>  因此，书中提出扎针理念是一种“关系范式”(relationshipparadigm),注重维护与客户的长久关系。但是这两种方法都忽略了人的社会属性，只专注于对个体进行研究，而忽略了他们所在社会网络对他们的影响作用，其可以表达为Oneto One。</p><h3 id="找人儿">1.3.3 找人儿</h3><p>  通过介绍意见领袖(opinion leader)、市场通(marketmaven)、社会枢纽(socialhub)，向我们展示了一个事实：客户是相互链接的。基于对通信案例的结论提出了几个可供思考的方向：首先，客户总是有意无意的链接在一起的，所以只针对单个客户的营销努力往往难以奏效。其次，客户的链接网络往往是存在枢纽或桥这样的关键节点，抓住关键更有助于营销人员开展营销实践。再次，网络结构依赖于实际的社会地位，能够成为社会网络的关键节点往往也是现实生活中综合实力的体现。最后，关系正在被数据化，线上数据平台已经成为人们真实关系的完美映射。这意味着“关系可编程”时代的到来，我们看待客户的视角必须做出改变。</p><p>  因此，找人儿是一种“网络范式”(network paradigm)，其表达为One to (Onein All)。</p><h3 id="进一步延伸">1.3.4 进一步延伸</h3><p>  梳理了以往各阶段学者对客户理解的研究，从产品范式到关系范式再到网络范式，都把客户排除在了企业生产之外，但是客户其实是可以深嵌其中的，甚至企业的价值创造和传递一刻离不开客户的参与。老师从火锅行业入手，对所看到的现象做出了梳理和总结。提出一旦打开用户参与的大门，将会切实改变价值的创造逻辑。并预言：未来，企业会与客户在价值创造的舞台上共舞！</p><h2 id="员工">1.4 员工</h2><p>  对于员工的研究要弄清楚三件事：一是员工本身；二是员工之间的关系；三是员工与企业的关系。想要了解企业业绩增长的引擎，就有必要将目光深入到组织内部，看看组织里的人以一种什么样的方式被组织起来。接下来深入介绍了几种组织方式。</p><h3 id="作坊式">1.4.1 作坊式</h3><p>  也就是传统的师傅带徒弟的方式。指出这种方式规范了竞争关系，将不同手艺人在同一个时间周期里的传承关系转变成了不同时间周期里的传承关系。该组织方式是以手艺为基础的，中心是将手艺转化为生产力，同时完成手艺传承与创新。</p><h3 id="工厂式">1.4.2 工厂式</h3><p>  工厂式与工艺流程相衔接，在这个过程中，摆脱了作坊式一人负责全部事务的弊端，每个工人负责一道工序。书中引用了《看得见的手——美国企业的管理革命》中的内容，认为这也使管理者开始在企业内部被分化出来，成为了一群虽然远离生产但却能够依靠贡献管理技能来取得报酬的人。</p><h3 id="写字楼式">1.4.3 写字楼式</h3><p>  代表着管理人员从地点上脱离出物质生产过程，转而负责对信息进行处理。这个过程中员工也进行生产活动，但是主要是开展信息、服务和创意方面的活动。与工厂的工人是流水线的附庸类似，写字楼里的办公人员也是“信息流水线”的附庸。只不过先相比于有形的流水线，办公人员却是被无形的信息系统所笼罩。</p><h3 id="云式">1.4.4 云式</h3><p>这种新型的组织形式使得信息处理者彻底的摆脱了时间和空间的束缚，不论在何时何地都能够与团队成员开展价值创造。同时也提出了几个思考：公司还是公司吗？员工还是员工吗？我在想，如果说员工方面可能是零工经济的话，那么公司方面会是一种怎样的新架构呢？</p><h3 id="组织进化">1.4.5 组织进化</h3><p>在介绍完企业空间上的组织方式后，书中从小到大阐述了一个企业内部组织方式的不断进化过程，并指出了很多时候公司无法完成从个人到企业整体的绩效转变。造成这种扭曲的原因在于“绩效协同”，即没有人的绩效是不依赖其他人而达成的。认为企业的整体绩效不应该的单个员工的简单累加，而应该是一种相乘的结果。</p><h2 id="感悟">1.5 感悟：</h2><p>产品、员工、客户的相互关系改进是企业价值创造效率提升的源泉，同时也要注意三条登山路径，从多个角度审视企业的价值创造过程。</p><p align="right">lukcy</p><p align="right">时2023年5月14日</p>]]></content>
    
    
    <categories>
      
      <category>蝶变三</category>
      
    </categories>
    
    
    <tags>
      
      <tag>蝶变</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>蝶变三_序章</title>
    <link href="/2023/05/13/%E8%9D%B6%E5%8F%98%E4%B8%89-%E5%BA%8F%E7%AB%A0/"/>
    <url>/2023/05/13/%E8%9D%B6%E5%8F%98%E4%B8%89-%E5%BA%8F%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>  接下来，将会开始阅读杨老师的《蝶变》系列，并进行整理归纳，总结感悟。该篇为蝶变三的序章 <span id="more"></span> # 序章  序章通过汽车行业的变迁反映各行业的"蝶变"之旅。</p><h2 id="汽车时代的来临与福特主义">1.汽车时代的来临与福特主义</h2><p>  第一部分主要介绍卡尔·本茨和贝瑞塔·本茨结束过去的马车时代开启全新汽车时代以及福特的流水线让汽车真正的开始走进千家万户。  其中福特流水线的逻辑在于：以时间换空间，即各零部件分散化生产、集中化转配。这一措施大大提高了生产效率，降低了生产成本，并慢慢的延伸到各产品的生产之中。</p><h2 id="社群自造">2.社群自造</h2><p>  福特的流水线使得工人沦为附庸，产品也变得单一，使得用户失去了对产品的选择权，而单个人又无法迫使企业做出改变。互联网的普及使得群体以社群的方式联合起来。LM的开源理念，使得用户重新掌握了对产品选择的主导权。将客户加入产品的生产过程中是一项有创造性的突围性的尝试。</p><h2 id="自动驾驶">3.自动驾驶</h2><p>  时间进入到计算机时代，计算机的快速发展，带动着大量数据的快速产生和流转，数据的出现不仅伴随着越来越大的量级，非结构化的程度也越来越高，使得许多传统的数据处理手段难以招架。一方面是处理大数据的需求，另一方面是计算机算力的提高，以深度学习为代表的机器学习算法蓬勃发展，成为了当今处理大数据的主要手段，新的算法使得诸多行业变得越来越智能化，众多互联网公司开启了诸多赛道展开比拼。</p><p>  在这个过程中，汽车行业的自动驾驶领域也成为赛道之一。这个过程一方面是“车进化”，另一方面是“路进化”。它们反映出了各行业完成智能化变革的关键——数据化。根据杨老师的观点，这个过程就是打造汽车智能引擎的过程。</p><h2 id="数据大脑">4.数据大脑</h2><p>  在介绍完汽车本身的智能引擎打造后，杨老师以滴滴为例，探寻了机器学习算法所打造的智能引擎对于运力系统的改变，介绍了一种“算法管理”的管理方式。这让骑手陷入了“时间——距离”的效率比拼陷阱之中。  这部分让我想到了福特的流水线生产，福特让工人被流水线禁锢，成为”工具人“，网约车司机不同的地方只是换了一个更加聪明的管理系统——算法。除此之外，二者有什么不同呢？正像杨老师提出的那样，也许系统直接驾驶汽车会是一个更好的选择。</p><h2 id="企业之车">5.企业之车</h2><p>  杨老师由汽车视角转向整个商业的发展进化，提出了本书的主旨：将智能思维引入企业经营实践，进而帮助企业家打造适应自身商业进化的智能引擎，从而重塑价值创造逻辑。</p><p align="right">lukcy</p><p align="right">时2023年5月13日</p>]]></content>
    
    
    <categories>
      
      <category>蝶变三</category>
      
    </categories>
    
    
    <tags>
      
      <tag>蝶变</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>蝶变：商业进化的智能引擎</title>
    <link href="/2023/05/13/%E8%9D%B6%E5%8F%98%EF%BC%9A%E5%95%86%E4%B8%9A%E8%BF%9B%E5%8C%96%E7%9A%84%E6%99%BA%E8%83%BD%E5%BC%95%E6%93%8E/"/>
    <url>/2023/05/13/%E8%9D%B6%E5%8F%98%EF%BC%9A%E5%95%86%E4%B8%9A%E8%BF%9B%E5%8C%96%E7%9A%84%E6%99%BA%E8%83%BD%E5%BC%95%E6%93%8E/</url>
    
    <content type="html"><![CDATA[<p>  接下来，将会开始阅读杨老师的《蝶变》系列，并进行整理归纳，总结感悟。<span id="more"></span></p>全文加上序章和后记共九章，按照每天一章进行，一方面总结内容，一方面写下感悟，注意结合当前智习室的研究方向做出思考。当前为5月13日，争取在下周一即5月22日前阅读并整理完第三部，写下相关感悟。<p align="right">lucky</p><p align="right">时2023年5月13日</p>]]></content>
    
    
    <categories>
      
      <category>蝶变三</category>
      
    </categories>
    
    
    <tags>
      
      <tag>蝶变</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>特征工程Part_6</title>
    <link href="/2023/05/12/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8BPart-6/"/>
    <url>/2023/05/12/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8BPart-6/</url>
    
    <content type="html"><![CDATA[<h1 id="telco-customer-churn-电信用户流失案例">Telco Customer Churn电信用户流失案例</h1><p>该篇为学习机器学习课程特征工程案例课整理笔记（代码部分只记录自己不太熟悉的）</p><p>接Part4部分</p><span id="more"></span><h2 id="决策树模型训练与结果解释">6.决策树模型训练与结果解释</h2><h3 id="建立benchmark">6.1 建立Benchmark</h3><p>  决策树对数据的要求并没有Logistic回归一样高，无需对分类变量进行独热编码，因此此处直接使用自然数编码。<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs clean"><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier  # 导入决策树评估器<br><br>tree_pre = ColumnTransformer([<br>    (<span class="hljs-string">&#x27;cat&#x27;</span>, OE(), category),<br>    (<span class="hljs-string">&#x27;num&#x27;</span>, <span class="hljs-string">&#x27;passthrough&#x27;</span>, numeric)<br>])  # 设置转化器流<br><br>tree_model = DecisionTreeClassifier()  # 实例化<br>tree_pipe = make_pipeline(tree_pre, tree_model)  # 设置机器学习流<br><br>tree_pipe.fit(X_train, y_train)  # 模型训练<br><br>result_df(tree_pipe, X_train, y_train, X_test, y_test)  # 显示评估指标结果<br></code></pre></td></tr></table></figure></p><h3 id="参数优化">6.2 参数优化</h3><p>  决策树的参数解释如下：</p><table><thead><tr class="header"><th style="text-align: center;">Name</th><th style="text-align: center;">Description</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">criterion</td><td style="text-align: center;">规则评估指标或损失函数，默认基尼系数，可选信息熵</td></tr><tr class="even"><td style="text-align: center;">splitter</td><td style="text-align: center;">树模型生长方式，默认以损失函数取值减少最快方式生长，可选随机根据某条件进行划分</td></tr><tr class="odd"><td style="text-align: center;">max_depth</td><td style="text-align: center;">树的最大生长深度，类似max_iter，即总共迭代几次</td></tr><tr class="even"><td style="text-align: center;">min_samples_split</td><td style="text-align: center;">内部节点再划分所需最小样本数</td></tr><tr class="odd"><td style="text-align: center;">min_samples_leaf</td><td style="text-align: center;">叶节点包含最少样本数</td></tr><tr class="even"><td style="text-align: center;">min_weight_fraction_leaf</td><td style="text-align: center;">叶节点所需最小权重和</td></tr><tr class="odd"><td style="text-align: center;">max_features</td><td style="text-align: center;">在进行切分时候最多带入多少个特征进行划分规则挑选</td></tr><tr class="even"><td style="text-align: center;">random_state</td><td style="text-align: center;">随机数种子</td></tr><tr class="odd"><td style="text-align: center;">max_leaf_nodes</td><td style="text-align: center;">叶节点最大个数</td></tr><tr class="even"><td style="text-align: center;">min_impurity_decrease</td><td style="text-align: center;">数据集再划分至少需要降低的损失值</td></tr><tr class="odd"><td style="text-align: center;">min_impurity_split</td><td style="text-align: center;">数据集再划分所需最低不纯度，将在0.25版本中移除</td></tr><tr class="even"><td style="text-align: center;">class_weight</td><td style="text-align: center;">各类样本权重</td></tr><tr class="odd"><td style="text-align: center;">presort</td><td style="text-align: center;">已在0.24版本中移除</td></tr><tr class="even"><td style="text-align: center;">ccp_alpha</td><td style="text-align: center;">在执行CART树原生原理中的剪枝流程时结构复杂度惩罚因子的系数，默认情况下不使用该方法进行剪枝</td></tr></tbody></table><p>ccp_alpha是决策树的结构风险系数，作用和Logistic回归中的C的作用类似，但二者取值刚好相反（ccp_alpha是结构风险系数，而C是经验风险系数）</p><p><span class="math display">\[R_\alpha(T) = R(T) + \alpha|\widetilde{T}|\]</span></p><p>下面将min_samples_split、min_impurity_decrease、max_leaf_nodes和ccp_alpha带入进行调参。</p><figure class="highlight roboconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs roboconf"><span class="hljs-comment"># tree_pipe.get_params()</span><br><span class="hljs-comment"># 构造包含阈值的参数空间</span><br>tree_param = &#123;&#x27;<span class="hljs-attribute">decisiontreeclassifier__ccp_alpha&#x27;</span>: np<span class="hljs-variable">.arange</span>(0, 1, 0.1)<span class="hljs-variable">.tolist</span>(),<br>              &#x27;decisiontreeclassifier__max_depth&#x27;: np<span class="hljs-variable">.arange</span>(2, 8, 1)<span class="hljs-variable">.tolist</span>(), <br>              &#x27;decisiontreeclassifier__min_samples_split&#x27;: np<span class="hljs-variable">.arange</span>(2, 5, 1)<span class="hljs-variable">.tolist</span>(), <br>              &#x27;decisiontreeclassifier__min_samples_leaf&#x27;: np<span class="hljs-variable">.arange</span>(1, 4, 1)<span class="hljs-variable">.tolist</span>(), <br>              &#x27;decisiontreeclassifier__max_leaf_nodes&#x27;:np<span class="hljs-variable">.arange</span>(6,10, 1)<span class="hljs-variable">.tolist</span>()<br>            &#125;<br><br></code></pre></td></tr></table></figure><h3 id="模型解释">6.3 模型解释</h3><ol type="1"><li>通过特征重要性</li></ol><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros">fi = tree_search.best_estimator_.name_steps[<span class="hljs-string">&#x27;decisiontreeclassifier&#x27;</span>].feature_importances_  # 特征重要性数值<br><br>col_names = category + numeric  # 特征名<br><br>feature_importances = pd.Series(fi, <span class="hljs-attribute">index</span>=col_names)<br>feature_importances.sort_values(<span class="hljs-attribute">ascending</span>=<span class="hljs-literal">False</span>)[:5].plot(<span class="hljs-attribute">kind</span>=<span class="hljs-string">&#x27;bar&#x27;</span>)<br><br></code></pre></td></tr></table></figure><blockquote><p>若要精准的计算于解释特征重要性，可以考虑使用SHAP方法。此外，目前尚未接触到的一类特征重要性的用途是借助进行特征筛选，下一部分在讨论特征筛选时会具体讲解。</p></blockquote><ol start="2" type="1"><li>绘制树状图</li></ol><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">plt.figure(figsize(<span class="hljs-number">16</span>,<span class="hljs-number">6</span>), dpi=<span class="hljs-number">200</span>)<br>tree.plot<span class="hljs-constructor">_tree(<span class="hljs-params">tree_search</span>.<span class="hljs-params">best_estimator_</span>.<span class="hljs-params">named_steps</span>[&#x27;<span class="hljs-params">decisiontreeclassifier</span>&#x27;])</span>;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>特征工程</tag>
      
      <tag>决策树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>特征工程_Part5</title>
    <link href="/2023/05/06/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Part5/"/>
    <url>/2023/05/06/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Part5/</url>
    
    <content type="html"><![CDATA[<h1 id="telco-customer-churn-电信用户流失案例">Telco Customer Churn电信用户流失案例</h1><p>该篇为学习机器学习课程特征工程案例课整理笔记（代码部分只记录自己不太熟悉的）</p><p>接Part4部分</p><span id="more"></span><h2 id="逻辑回归的进阶调优与模型解释">5.逻辑回归的进阶调优与模型解释</h2><p>逻辑回归的判别阈值也可以作为超参数进行调整，但是sklearn中并未提供该参数，因此下面将自定义评估器。</p><h3 id="阈值调优">5.1阈值调优</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python">********************************重要*********************************<br><span class="hljs-keyword">from</span> sklearn.base <span class="hljs-keyword">import</span> BaseEstimator, TransformerMixin<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">logit_threshold</span>(<span class="hljs-params">BaseEstimator, TransformerMixin</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, penalty=<span class="hljs-string">&#x27;l2&#x27;</span>, C=<span class="hljs-number">1.0</span>, max_iter=<span class="hljs-number">1e8</span>, solver=<span class="hljs-string">&#x27;lbfgs&#x27;</span>, l1_ratio=<span class="hljs-literal">None</span>, class_weight=<span class="hljs-literal">None</span>, thr=<span class="hljs-number">0.5</span></span>):</span><br>        self.penalty = penalty<br>        self.C = C<br>        self.max_iter = max_iter<br>        self.solver = solver<br>        self.l1_ratio = l1_ratio<br>        self.thr = thr<br>        self.class_weight = class_weight<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">self, X, y</span>):</span><br>        clf = LogisticRegression(<br>            penalty = self.penalty<br>            , C = self.C<br>            , solver = self.solver<br>            , l1_ratio = self.l1_ratio<br>            , class_weight = self.class_weight<br>            , max_iter = self.max_iter<br>        )<br>        clf.fit(X, y)<br>        self.coef_ = clf.coef_<br>        self.clf = clf<br>        <span class="hljs-keyword">return</span> self<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">score</span>(<span class="hljs-params">self, X, y</span>):</span><br>        score = self.clf.score(X, y)<br>        <span class="hljs-keyword">return</span> score<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span>(<span class="hljs-params">self, X</span>):</span><br>        res = (self.clf.predict_proba(X)[:,<span class="hljs-number">1</span>]&gt;=self.thr) * <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></table></figure><p>之后继续进行搜索即可，具体代码见Part3.</p><h3 id="class_weight-调优">5.2 class_weight 调优</h3><p>  一般来说，如果是3:1的样本比例，class_weight的参数取值基本可以设置在2:1=4:1之间，也可以考虑使用样本量的反比，在sklearn中为balance参数</p><h3 id="模型解释">5.3 模型解释</h3><h4 id="系数查看">5.3.1 系数查看</h4><p><code>coef = logistic_search.best_estimator_.named_steps['logit_threshold'].coef_  # 定位到逻辑回归评估器调出其参数</code></p><p>将系数与字段名相结合查看具体含义 <figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs routeros">oht = logistic_search.best_estimator_.named_steps[<span class="hljs-string">&#x27;columntransformer&#x27;</span>].named_transformers_[<span class="hljs-string">&#x27;cat&#x27;</span>]  # 定位到独热编码转换器<br><br><span class="hljs-comment"># 转化后离散变量列名称</span><br>category_cols_new = cate_colName(tf, category_cols)<br><br><span class="hljs-comment"># 所有字段名称</span><br>cols_new = category_cols_new + numeric_cols<br><br><span class="hljs-comment"># 查看特征名称数量和特征系数数量是否一致</span><br>assert len(cols_new) == len(coe)<br><br>weights = pd.Series(coe, <span class="hljs-attribute">index</span>=cols_new)<br><br><span class="hljs-comment"># 可视化展示取值最大和最小的10个自变量系数</span><br>plt.figure(figsize=(16, 6), <span class="hljs-attribute">dpi</span>=200)<br><br><span class="hljs-comment"># 挑选正相关的前10个变量</span><br>plt.subplot(121)<br>weights.sort_values(ascending = <span class="hljs-literal">False</span>)[:10].plot(<span class="hljs-attribute">kind</span>=<span class="hljs-string">&#x27;bar&#x27;</span>)<br><br><span class="hljs-comment"># 挑选负相关的前10个变量</span><br>plt.subplot(122)<br>weights.sort_values(ascending = <span class="hljs-literal">False</span>)[-10:].plot(<span class="hljs-attribute">kind</span>=<span class="hljs-string">&#x27;bar&#x27;</span>);<br></code></pre></td></tr></table></figure></p><h4 id="系数解释">5.3.2 系数解释</h4><p>  逻辑回归方程如下(假设训练的方程为1-x): <span class="math display">\[y=\frac{1}{1+e^{-(1-x)}}\]</span>   进一步推导可得: <span class="math display">\[ln{\frac{y}{1-y}}= 1-x\]</span> 可解释为x每增加1，样本的对数几率就减少1一般如果对数几率增加50%，概率大约增加10%</p><h2 id="模型总结">5.4 模型总结</h2><ol type="1"><li>模型性能方面</li></ol><p>  通过上述尝试，我们基本能判断逻辑回归模型在当前数据集的性能，准确率约在80%左右，准确率没有太大的超参数调优搜索空间，而f1-Score则在我们额外设置的超参数——阈值上能够有更好的搜索结果。</p><ol start="2" type="1"><li>超参数调优方面</li></ol><p>  sklearn中的逻辑回归超参数众多，在算力允许的情况下，建议尽量设置更多的迭代次数（max_iter）和更小的收敛条件（tol），基本的搜索参数为正则化项（penalty）+经验风险系数（C）+求解器（solver），如果算力允许，可以纳入弹性网正则化项进行搜索，并搜索l1正则化项权重系数（l1_ratio）。若样本存在样本不均衡，可带入class_weight进行搜索，若搜索目标是提升f1-Score或ROC-AUC，则可通过自定义评估器进行阈值移动，若希望进行更加精确的搜索，可以纳入连续变量的编码方式进行搜索。</p><ol start="3" type="1"><li>阈值移动与样本权重调节方面</li></ol><p>根据上面的实验结果，对于阈值调优和样本权重调优可以进行如下总结：<br>  (1)阈值移动往往出现在f1-Score调优或ROC-AUC调优的场景中，由于阈值移动对召回率、精确度等指标调整效果显著，因此该参数的搜索往往效果要好于逻辑回归其他默认参数，类似的情况也出现在其他能够输出概率结果的模型中（如决策树、随机森林等）；<br>  (2)样本权重调节往往出现在非平衡类数据集的建模场景中，通过该参数的设置，能够让模型在训练过程中更加关注少数类样本，从而一定程度起到平衡数据集不同类别样本的目的，并且相比于其他平衡样本方法（例如过采样、欠采样、SMOTEENN等），该方法能够更好的避免过拟合，并且该参数同样也是一个通用参数，出现在sklearn集成的诸多模型中。建议如果算力允许，可以在任何指标调整过程中对该参数进行搜索；<br>  (3)不过如果是围绕f1-Score或ROC-AUC进行调优，阈值移动和样本权重调节会有功能上的重复，此时建议优先选用阈值进行搜索。</p><ol start="4" type="1"><li>模型解释方面</li></ol><p>  对于逻辑回归来说，模型可解释性的核心在于模型是线性方程，据此我们可以根据线性方程中自变量的系数对其进行结果解读，包括自变量变化如何影响因变量，以及自变量之间的相对关系等。</p><p align="right">lucky</p><p align="right">时23年6月5日</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>特征工程</tag>
      
      <tag>进阶调优</tag>
      
      <tag>模型解释</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>特征工程_Part4</title>
    <link href="/2023/05/06/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Part4/"/>
    <url>/2023/05/06/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Part4/</url>
    
    <content type="html"><![CDATA[<h1 id="telco-customer-churn-电信用户流失案例">Telco Customer Churn电信用户流失案例</h1><p>  该篇为学习机器学习课程特征工程案例课整理笔记（代码部分只记录自己不太熟悉的）</p><p>接Part3部分 <span id="more"></span></p><h2 id="逻辑回归模型训练与结果解释">4.逻辑回归模型训练与结果解释</h2><h3 id="设置评估指标与测试集">4.1设置评估指标与测试集</h3><p>  需要知道的是，一般在二分类预测问题中，0：1在3：1左右是一个重要界限，若0：1小于3：1，则标签偏态基本可以忽略不计，不需要进行偏态样本处理（处理了也容易过拟合），同时在模型评估指标选取时也可以直接选择“中立”评估指标，如准确率或者roc-auc。而如果0：1大于3：1，则认为标签取值分布存在偏态，需要对其进行处理，如过采样、欠采样、或者模型组合训练、或者样本聚类等，并且如果此时需要重点衡量模型对1类识别能力的话，则更加推荐选择f1-Score。<figure class="highlight capnproto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs capnproto"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score, recall_score, precision_score, f1_score, roc_auc_score   <span class="hljs-comment"># 导入评估指标</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split   <span class="hljs-comment"># 导入训练测试集划分工具</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV  <span class="hljs-comment"># 导入网格搜索</span><br><span class="hljs-keyword">import</span> time <span class="hljs-comment"># 模型训练时用来记录训练时间</span><br><br>train, test = train_test_split(tcc, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">21</span>)<br></code></pre></td></tr></table></figure></p><h3 id="逻辑回归模型训练">4.2 逻辑回归模型训练</h3><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs nix">from sklearn.linear_model <span class="hljs-built_in">import</span> LogisticRegression  <span class="hljs-comment"># 导入逻辑回归算法</span><br>from sklearn.pipeline <span class="hljs-built_in">import</span> make_pipline  <span class="hljs-comment"># 导入机器学习流</span><br><br><br><span class="hljs-comment"># 划分特征和标签</span><br><span class="hljs-attr">X_train</span> = train.drop(<span class="hljs-attr">columns=[ID_col,</span> target]).copy()<br><span class="hljs-attr">y_train</span> = train[&#x27;Churn&#x27;].copy()<br><span class="hljs-attr">X_test</span> = test.drop(<span class="hljs-attr">columns=[ID_col,</span> target]).copy()<br><span class="hljs-attr">y_train</span> = test[&#x27;Churn&#x27;].copy()<br><br><br><span class="hljs-comment"># 设置转换器与评估器</span><br><span class="hljs-attr">logistic_pre</span> = ColumnTransformer([<br>    (&#x27;cat&#x27;, OHE, category),<br>    (&#x27;num&#x27;, &#x27;passthrough&#x27;, numeric)<br>])  <span class="hljs-comment"># 转化器流</span><br><span class="hljs-attr">logistic_model</span> = LogisticRegression(<span class="hljs-attr">max_iter=int(1e8))</span>  <span class="hljs-comment"># 模型实例化</span><br><br><span class="hljs-attr">logistic_pipe</span> = make_pipeline(logistic_pre, logistic_model)  <span class="hljs-comment"># 集成为一个机器学习工作流</span><br><br><span class="hljs-comment"># 模型训练</span><br>logistic_pipe.fit(X_train, y_train)<br>*********************************重点***********************************<br><span class="hljs-comment"># 查看模型结果</span><br>logistic_pipe.score(X_train, y_train)  <span class="hljs-comment"># 查看得分</span><br><span class="hljs-comment"># 构建函数计算多个评估指标结果</span><br><br><span class="hljs-attr">metrics</span> = [accuracy_score, recall_score, precision_score, f1_score, roc_auc_score]<br><br>def result_df(model, X_train, X_test, y_train, y_test, <span class="hljs-attr">metrics=[accuracy_score,</span> recall_score, precision_score, f1_score, roc_auc_score]):<br>    <span class="hljs-attr">res_train</span> = []<br>    <span class="hljs-attr">res_test</span> = []<br>    <span class="hljs-attr">col_name</span> = []<br>    for m <span class="hljs-keyword">in</span> metrics:<br>        res_train.append(m(model.predict(X_train), y_train))  <span class="hljs-comment"># 计算训练集评估指标</span><br>        res_test.append(m(model.predict(X_test), ytest))  <span class="hljs-comment"># 计算测试集评估指标</span><br>        col_name.append(m.__name__)<br>    <span class="hljs-attr">idx_name</span> = [<span class="hljs-string">&quot;train_eval&quot;</span>, <span class="hljs-string">&quot;test_eval&quot;</span>]<br>    <span class="hljs-attr">res</span> = pd.DataFrame([res_train, res_test], <span class="hljs-attr">columns=col_name,</span> <span class="hljs-attr">index=idx_name)</span><br>    return res<br><br>result_df(logistic_pipe, X_train, X_test, y_train, y_test)  <span class="hljs-comment"># 查看模型结果</span><br></code></pre></td></tr></table></figure><h3 id="逻辑回归的超参数调优">4.3 逻辑回归的超参数调优</h3><p>以下为逻辑回归评估器的参数解释</p><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">解释</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">penalty</td><td style="text-align: center;">正则化项</td></tr><tr class="even"><td style="text-align: center;">dual</td><td style="text-align: center;">是否求解对偶问题*</td></tr><tr class="odd"><td style="text-align: center;">tol</td><td style="text-align: center;">迭代停止条件：两轮迭代损失值差值小于tol时，停止迭代</td></tr><tr class="even"><td style="text-align: center;">C</td><td style="text-align: center;">经验风险和结构风险在损失函数中的权重</td></tr><tr class="odd"><td style="text-align: center;">fit_intercept</td><td style="text-align: center;">线性方程中是否包含截距项</td></tr><tr class="even"><td style="text-align: center;">intercept_scaling</td><td style="text-align: center;">相当于此前讨论的特征最后一列全为1的列，当使用liblinear求解参数时用于捕获截距</td></tr><tr class="odd"><td style="text-align: center;">class_weight</td><td style="text-align: center;">各类样本权重*</td></tr><tr class="even"><td style="text-align: center;">random_state</td><td style="text-align: center;">随机数种子</td></tr><tr class="odd"><td style="text-align: center;">solver</td><td style="text-align: center;">损失函数求解方法*</td></tr><tr class="even"><td style="text-align: center;">max_iter</td><td style="text-align: center;">求解参数时最大迭代次数，迭代过程满足max_iter或tol其一即停止迭代</td></tr><tr class="odd"><td style="text-align: center;">multi_class</td><td style="text-align: center;">多分类问题时求解方法*</td></tr><tr class="even"><td style="text-align: center;">verbose</td><td style="text-align: center;">是否输出任务进程</td></tr><tr class="odd"><td style="text-align: center;">warm_start</td><td style="text-align: center;">是否使用上次训练结果作为本次运行初始参数</td></tr><tr class="even"><td style="text-align: center;">l1_ratio</td><td style="text-align: center;">当采用弹性网正则化时，<span class="math inline">\(l1\)</span>正则项权重，就是损失函数中的<span class="math inline">\(\rho\)</span></td></tr></tbody></table><p>  在这些所有超参数中，对模型结果影响较大的参数主要有两类，其一是正则化项的选择，同时也包括经验风险项的系数与损失求解方法选择，第二类则是迭代限制条件，主要是max_iter和tol两个参数，当然，在数据量较小、算力允许的情况下，我们也可以直接设置较大max_iter、同时设置较小tol数值。由于我们并未考虑带入数据本身的膨胀系数（共线性），因此此处我们优先考虑围绕经验风险系数与正则化选择类参数进行搜索与优化。<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 检验列是否划分完全</span><br>assert len(category) + len(numeric) == X_train.shape[1]<br><br><span class="hljs-comment"># 设置转化器流</span><br>logistic_pre = ColumnTransformer([<br>    (<span class="hljs-string">&#x27;cat&#x27;</span>, preprocessing.OneHotEncoder(<span class="hljs-attribute">drop</span>=<span class="hljs-string">&#x27;if_binary&#x27;</span>), category_cols), <br>    (<span class="hljs-string">&#x27;num&#x27;</span>, <span class="hljs-string">&#x27;passthrough&#x27;</span>, numeric_cols)<br>])<br><span class="hljs-comment"># 连续变量预处理</span><br>num_pre = [<span class="hljs-string">&#x27;passthrough&#x27;</span>, preprocessing.StandardScaler(), preprocessing.KBinsDiscretizer(<span class="hljs-attribute">n_bins</span>=3, <span class="hljs-attribute">encode</span>=<span class="hljs-string">&#x27;ordinal&#x27;</span>, <span class="hljs-attribute">strategy</span>=<span class="hljs-string">&#x27;kmeans&#x27;</span>)]<br><span class="hljs-comment"># 实例化逻辑回归评估器</span><br>logistic_model = LogisticRegression(<span class="hljs-attribute">max_iter</span>=int(1e8))<br><br><span class="hljs-comment"># 设置机器学习流</span><br>logistic_pipe = make_pipeline(logistic_pre, logistic_model)<br>*********************************重点***********************************<br>logistic_pipe.get_params()<br><br><span class="hljs-comment"># 构建超参数空间</span><br>logistic_param = [<br>    &#123;<span class="hljs-string">&#x27;columntransformer__num&#x27;</span>:num_pre,<span class="hljs-string">&#x27;logisticregression__penalty&#x27;</span>: [<span class="hljs-string">&#x27;l1&#x27;</span>], <span class="hljs-string">&#x27;logisticregression__C&#x27;</span>: np.arange(0.1,2.1, 0.1).tolist(), <span class="hljs-string">&#x27;logisticregression__solver&#x27;</span>:[<span class="hljs-string">&#x27;saga&#x27;</span>]&#125;<br><br>    , &#123;<span class="hljs-string">&#x27;columntransformer__num&#x27;</span>:num_pre,<span class="hljs-string">&#x27;logisticregression__penalty&#x27;</span>:[<span class="hljs-string">&#x27;l2&#x27;</span>], <span class="hljs-string">&#x27;logisticregression__C&#x27;</span>:np.arange(0.1,2.1, 0.1).tolist(), <span class="hljs-string">&#x27;logisticregression__solver&#x27;</span>:[<span class="hljs-string">&#x27;lbfgs&#x27;</span>, <span class="hljs-string">&#x27;newton-cg&#x27;</span>, <span class="hljs-string">&#x27;saga&#x27;</span>]&#125;<br><br>    , &#123;<span class="hljs-string">&#x27;columntransformer__num&#x27;</span>:num_pre,<span class="hljs-string">&#x27;logisticregression_penalty&#x27;</span>:[<span class="hljs-string">&#x27;elasticnet&#x27;</span>], <span class="hljs-string">&#x27;logisticregression__C&#x27;</span>:np.arange(0.1, 2.1, 0.1).tolist(), <span class="hljs-string">&#x27;logisticregression__l1_ratio&#x27;</span>:np.arange(0.1, 1.1, 0.1).tolist(), <span class="hljs-string">&#x27;logisticregression__solver&#x27;</span>: [<span class="hljs-string">&#x27;saga&#x27;</span>]&#125;<br>]<br>logistic_search = GridSearchCV(<span class="hljs-attribute">estimator</span>=logistic_pipe<br>                            , param_grid = logistic_param<br>                            , scoring = <span class="hljs-string">&#x27;accuracy&#x27;</span> # 这里按照准确率进行搜索，可以改为f1或者roc_auc<br>                            , <span class="hljs-attribute">n_jobs</span>=-1)  # 实例化网格搜索评估器<br><br>start = time.time()<br>logistic_search.fit(X_train, y_train)<br><span class="hljs-builtin-name">print</span>(time.time()-s, <span class="hljs-string">&quot;s&quot;</span>)<br></code></pre></td></tr></table></figure></p><blockquote><p>可考虑使用贝叶斯优化进行训练，可以大大增加搜索效率</p></blockquote><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">logistic_search.<span class="hljs-keyword">best_score_ </span> <span class="hljs-comment"># 查看最优分数</span><br>logistic_search.<span class="hljs-keyword">best_params_ </span> <span class="hljs-comment"># 最优参数组合</span><br>logistic_search.<span class="hljs-keyword">best_estimator_ </span><span class="hljs-comment">#  最优评估器</span><br>result_df(logistic_search.<span class="hljs-keyword">best_estimator_, </span>X_train, X_test, y_train, y_test)   <span class="hljs-comment"># 输出结果</span><br></code></pre></td></tr></table></figure><p align="right">lucky</p><p align="right">时23年6月5日</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>特征工程</tag>
      
      <tag>模型训练</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>特征工程_Part3</title>
    <link href="/2023/05/05/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Part3/"/>
    <url>/2023/05/05/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Part3/</url>
    
    <content type="html"><![CDATA[<h1 id="telco-customer-churn-电信用户流失案例">Telco Customer Churn电信用户流失案例</h1><p>该篇为学习机器学习课程特征工程案例课整理笔记（代码部分只记录自己不太熟悉的）</p><p>接Part2部分 <span id="more"></span></p><h2 id="连续字段的特征变换">3.连续字段的特征变换</h2><h3 id="标准化与归一化">3.1 标准化与归一化</h3><p>  从功能上划分，sklearn中的归一化其实是分为标准化（Standardization）和归一化（Normalization）两类。其中，此前所介绍的Z-Score标准化和0-1标准化，都属于Standardization的范畴，而在sklearn中，Normalization则特指针对单个样本（一行数据）利用其范数进行放缩的过程。不过二者都属于数据预处理范畴，都在sklearn中的Preprocessingdata模块下。</p><p><em>需要注意的是，此前我们介绍数据归一化时有讨论过标准化和归一化名称上的区别，在大多数场景下其实我们并不会对其进行特意的区分，但sklearn中标准化和归一化则各指代一类数据处理方法，此处需要注意。</em></p><h4 id="z-score标准化">3.1.1 Z-score标准化</h4><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">from sklearn.preprocessing import StandardScaler  <span class="hljs-comment"># 导入</span><br><span class="hljs-keyword">scaler_1 </span>= StandardScaler()  <span class="hljs-comment"># 实例化</span><br><span class="hljs-keyword">scaler_1.fit(X) </span>  <span class="hljs-comment"># 训练</span><br><span class="hljs-keyword">scaler_1.scale_ </span> <span class="hljs-comment"># 属性查看标准差</span><br><span class="hljs-keyword">scaler_1.mean_ </span> <span class="hljs-comment"># 属性查看均值</span><br><span class="hljs-keyword">scaler_1.var_ </span> <span class="hljs-comment"># 属性查看方差</span><br><span class="hljs-keyword">scaler_1.n_samples_seen_ </span> <span class="hljs-comment"># 属性查看有效的训练数据数量</span><br></code></pre></td></tr></table></figure><h4 id="标准化">3.1.2 0-1标准化</h4><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">from sklearn.preprocessing import MinMaxScaler  <span class="hljs-comment"># 导入</span><br><span class="hljs-keyword">scaler_2 </span>= MinMaxScaler()  <span class="hljs-comment"># 实例化</span><br><span class="hljs-keyword">scaler_2.fit_transform(X) </span>  <span class="hljs-comment"># 训练</span><br><span class="hljs-keyword">scaler_2.data_min_ </span> <span class="hljs-comment"># 属性查看最小值</span><br><span class="hljs-keyword">scaler_2.data_max_ </span> <span class="hljs-comment"># 属性查看最大值</span><br></code></pre></td></tr></table></figure><h4 id="归一化normalization">3.1.3 归一化Normalization</h4><p>1.范数</p><p>  此前我们曾解释到关于范数的基本概念，假设向量<span class="math inline">\(x = [x_1, x_2, ...,x_n]^T\)</span>，则向量x的1-范数的基本计算公式为： <span class="math display">\[||x||_1 = |x_1|+|x_2|+...+|x_n|\]</span> 即各分量的绝对值之和。而向量x的2-范数计算公式为： <span class="math display">\[||x||_2 = \sqrt{(|x_1|^2+|x_2|^2+...+|x_n|^2)}\]</span> 即各分量的平方和再开平方。</p><p>  而sklearn中的Normalization过程，实际上就是将每一行数据视作一个向量，然后用每一行数据去除以该行数据的1-范数或者2-范数。具体除以哪个范数，以preprocessing.normalize函数中输入的norm参数为准。</p><p>method_1:</p><p><code>preprocessing.normalize(X, norm='l1')</code></p><p><code>preprocessing.normalize(X, norm='l2')</code></p><p>method_2:</p><p><code>X / np.linalg.norm(X, ord=1 axis=1).reshape(5,1)</code></p><p><code>X / np.linalg.norm(X, ord=2, axis=1)</code></p><p><code>X / np.sqrt(np.sum(np.power(X, 2), axis=1))# 与上一个效果相同</code></p><p>method_3: <figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">from sklearn.preprocessing import Normalizer<br>normalize = <span class="hljs-constructor">Normalizer(<span class="hljs-params">norm</span>=&#x27;<span class="hljs-params">l1</span>&#x27;)</span><br>normalize.fit<span class="hljs-constructor">_transform(X)</span><br></code></pre></td></tr></table></figure></p><h3 id="连续变量的分箱">3.2连续变量的分箱</h3><p>一般根据具体的业务流程或计算流程进行分箱 <figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">from</span> sklearn.preprocessing import KBinDiscretizer<br>dis_1 = KBinDiscretizer(<span class="hljs-attribute">n_bins</span>=3, <span class="hljs-attribute">encode</span>=<span class="hljs-string">&quot;ordinal&quot;</span>, <span class="hljs-attribute">strategy</span>=<span class="hljs-string">&quot;uniform&quot;</span>)  # 等宽分箱<br>dis_2 = KBinDiscretizer(<span class="hljs-attribute">n_bins</span>=3, <span class="hljs-attribute">encode</span>=<span class="hljs-string">&quot;ordinal&quot;</span>, <span class="hljs-attribute">strategy</span>=<span class="hljs-string">&quot;quantile&quot;</span>)  # 等频分箱<br>dis_3 = KBinDiscretizer(<span class="hljs-attribute">n_bins</span>=3, <span class="hljs-attribute">encode</span>=<span class="hljs-string">&#x27;ordinal&#x27;</span>, <span class="hljs-attribute">strategy</span>=<span class="hljs-string">&#x27;kmeans&#x27;</span>)  # 聚类分箱<br>dis_1.fit_transform(income) # 训练<br>dis_1.bin_edges_ # 划分边界<br></code></pre></td></tr></table></figure></p><h3 id="columntransformer集成连续变量">3.3ColumnTransformer集成连续变量</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros">ColumnTransformer([<br>    (<span class="hljs-string">&#x27;cat&#x27;</span>, OHE(<span class="hljs-attribute">drop</span>=<span class="hljs-string">&#x27;if_binary&#x27;</span>), catgory),<br>    (<span class="hljs-string">&#x27;num&#x27;</span>, KBinDiscretizer(<span class="hljs-attribute">n_bins</span>=3, <span class="hljs-attribute">encode</span>=<span class="hljs-string">&#x27;ordinal&#x27;</span>, <span class="hljs-attribute">strategy</span>=<span class="hljs-string">&#x27;kmeans&#x27;</span>), numeric)<br>])<br></code></pre></td></tr></table></figure><p align="right">lucky</p><p align="right">时23年5月6日</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>特征工程</tag>
      
      <tag>离散变量重编码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>特征工程_Part2</title>
    <link href="/2023/05/05/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Part2/"/>
    <url>/2023/05/05/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Part2/</url>
    
    <content type="html"><![CDATA[<h1 id="telco-customer-churn-电信用户流失案例">Telco Customer Churn电信用户流失案例</h1><p>该篇为学习机器学习课程特征工程案例课整理笔记（代码部分只记录自己不太熟悉的）</p><p>接Part1部分</p><span id="more"></span><p>上节处理代码</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> numpy as np<br><span class="hljs-built_in">import</span> pandas as pd<br><span class="hljs-built_in">import</span> seaborn as sns<br><span class="hljs-built_in">import</span> matplotlib.pyplot as plt<br><span class="hljs-attr">tcc</span> = pd.read_csv(<span class="hljs-string">&quot;&quot;</span>, <span class="hljs-attr">index_col=0)</span><br><span class="hljs-comment">### 预处理</span><br><span class="hljs-attr">category</span> = []<span class="hljs-comment"># 离散</span><br><span class="hljs-attr">numeric</span> = []<span class="hljs-comment"># 连续</span><br><span class="hljs-attr">target</span> = <span class="hljs-string">&quot;Churn&quot;</span><span class="hljs-comment"># 标签</span><br><br>tcc[<span class="hljs-string">&quot;features&quot;</span>] = tcc[<span class="hljs-string">&quot;features&quot;</span>].apply(lambda x :x <span class="hljs-keyword">if</span> x!=&#x27; &#x27; <span class="hljs-keyword">else</span> np.nan)<br>tcc[<span class="hljs-string">&quot;features&quot;</span>] = tcc[<span class="hljs-string">&quot;features&quot;</span>].astype(float)<br><br>tcc[<span class="hljs-string">&quot;features&quot;</span>] = tcc[<span class="hljs-string">&quot;features&quot;</span>].fillna(<span class="hljs-number">0</span>)<span class="hljs-comment"># 缺失按0处理</span><br><br>tcc[<span class="hljs-string">&quot;Churn&quot;</span>].replace(<span class="hljs-attr">to_replace=&quot;Yes&quot;,</span> <span class="hljs-attr">value=1,</span> <span class="hljs-attr">inplace=True)</span><br>tcc[<span class="hljs-string">&quot;Churn&quot;</span>].replace(<span class="hljs-attr">to_replace=&quot;No&quot;,</span> <span class="hljs-attr">value=0,</span> <span class="hljs-attr">inplace=False)</span><br></code></pre></td></tr></table></figure><h2 id="离散字段的数据重编码">2.离散字段的数据重编码</h2><h3 id="ordinalencoder">2.1 OrdinalEncoder</h3><p>method_1:<code>DataFrame.replace()</code>method_2:<code>sklearn.preprocessing.OrdinalEncoder</code>下面着重介绍method_2 <figure class="highlight capnproto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs capnproto"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> OrdinalEncoder <span class="hljs-keyword">as</span> OE<br>enc_1 = OE() <span class="hljs-comment"># 实例化</span><br>enc_1.fit_transformer(X).toarray() <span class="hljs-comment"># 训练</span><br>enc_1.categories_ <span class="hljs-comment"># 查看属性</span><br></code></pre></td></tr></table></figure></p><h3 id="onehotencoder">2.2 OneHotEncoder</h3><p>method_1:<code>pd.get_dummies()</code>method_2:<code>sklearn.preprocessing.OneHotEncoder</code></p><p><em>注意:二分类特征独热编码从理论上来说没有效果</em> <figure class="highlight capnproto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs capnproto"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> OneHotEncoder <span class="hljs-keyword">as</span> OHE<br>enc_2 = OHE(drop=<span class="hljs-string">&quot;if_binary&quot;</span>) <span class="hljs-comment"># 实例化, drop属性表示二分类特征不进行独热编码</span><br>enc_2.fit_transformer(X).toarray() <span class="hljs-comment"># 训练</span><br>enc_2.categories_ <span class="hljs-comment"># 查看属性</span><br></code></pre></td></tr></table></figure>由于独热编码转化器不能生成列名称，故封装一个函数创造独热编码后的列名<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs vim">def cate_colName(Transformer, category_cols, <span class="hljs-keyword">drop</span>=<span class="hljs-string">&quot;if_binary&quot;</span>):<br>    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br>    OneHotEncoder()后列名创造函数<br>    :param Transformer: 转换器<br>    :param category: 离散变量名(<span class="hljs-keyword">list</span>)<br>    :param <span class="hljs-keyword">drop</span>: 转换器中是否排除二分类<br><br>    cate_cols_new = []<br>    col_value = Transformer.categories_<br><br>    <span class="hljs-keyword">for</span> i,<span class="hljs-keyword">j</span> in enumerate(category_cols):<br>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">drop</span> == <span class="hljs-string">&quot;if_binary&quot;</span>) &amp; (<span class="hljs-built_in">len</span>(col_value[i] == <span class="hljs-number">2</span>)):<br>            cate_cols_new.<span class="hljs-keyword">append</span>(<span class="hljs-keyword">j</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">for</span> <span class="hljs-keyword">f</span> in col_value[i]:<br>                feature_name = <span class="hljs-keyword">j</span> + <span class="hljs-string">&quot;_&quot;</span> + <span class="hljs-keyword">f</span><br>                cate_cols_new.<span class="hljs-keyword">append</span>(feature_name)<br>    <span class="hljs-keyword">return</span> cate_cols_new<br></code></pre></td></tr></table></figure></p><h3 id="columntransformer">2.3 ColumnTransformer</h3>该工具可以集成多个转化器，使得数据处理更加自动化，这样可以将几个预处理的步骤集成到一起<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs nix">from sklearn.compose <span class="hljs-built_in">import</span> ColumnTransformer<br><br><span class="hljs-attr">preprocess_col</span> = <span class="hljs-attr">preprocess_col</span> = ColumnTransformer([<br>    (<span class="hljs-string">&quot;cat&quot;</span>, OHE(<span class="hljs-attr">drop=&quot;if_binary),</span> categoty)<br>    , (<span class="hljs-string">&quot;num&quot;</span>, <span class="hljs-string">&quot;passthrough&quot;</span>, numeric)<br>])  <span class="hljs-comment"># 实例化</span><br><br>preprocess_col.fit_transform(X) <span class="hljs-comment"># </span><br><br>preprocess_col.named_transformers_ <span class="hljs-comment"># 查看转换器，需要查看其内部的转换器可以直接索引</span><br></code></pre></td></tr></table></figure> 据此可知，该转换器的基本格式为：<p align="center">(评估器名称（自定义）, 转化器, 数据集字段（转化器作用的字段）)</p><p align="right">lucky</p><p align="right">时23年5月5日</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>特征工程</tag>
      
      <tag>离散变量重编码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>特征工程_Part1</title>
    <link href="/2023/05/05/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Part1/"/>
    <url>/2023/05/05/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-Part1/</url>
    
    <content type="html"><![CDATA[<h1 id="telco-customer-churn-电信用户流失案例">Telco Customer Churn电信用户流失案例</h1><p>该篇为学习机器学习课程特征工程案例课整理笔记（代码部分只记录自己不太熟悉的）<span id="more"></span> 机器学习基本建模流程如下： <img src="/images/机器学习/特征工程/流程图.jpg"></p><h2 id="数据背景与数据探索">1 数据背景与数据探索</h2><h3 id="业务背景">1.1 业务背景</h3><p>  在数字时代，传统的大众营销已经失去优势，如何基于用户信息和行为，来进行更加精准的营销，从而满足用户更加多样化、层次化和个性化的需求，成为所有电信运营商必须面对的课题。而于此同时，电信的公共客户（个人或家庭用户）用户又同时具有易变性、发展性和替代性等特点，且用户需求弹性较小，外加普通用户购买电信产品周期较长，导致在实际的交易关系中，电信公司对公共客户获客较难、主动拓展新用户成本较高，因此维系既有用户、防止用户流失就成了重要的运营策略。</p><h3 id="建模目标">1.2 建模目标</h3><ol type="1"><li>对流失用户进行预测</li><li>找出影响用户流失的重要因子</li></ol><h2 id="数据解读与预处理">2 数据解读与预处理</h2><p><code>tcc.info()  # 数据概况</code></p><ol type="1"><li><p>数据正确性校验：判断有无重复数据</p></li><li><p>缺失值检验 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">missing</span>(<span class="hljs-params">df</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    计算每一列的缺失值及占比</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    missing_number = df.isnull().<span class="hljs-built_in">sum</span>().sort_values(ascending=<span class="hljs-literal">False</span>)<br>    missing_percent = (df.isnull().<span class="hljs-built_in">sum</span>()/df.isnull().count()).sort_values(ascending=<span class="hljs-literal">False</span>)<br>    missing_values = pd.concat([missing_number, missing_percent], keys=[<span class="hljs-string">&quot;missing_number&quot;</span>, <span class="hljs-string">&quot;missing_percent&quot;</span>])<br><br>    <span class="hljs-keyword">return</span> missing_values<br><br></code></pre></td></tr></table></figure></p></li><li><p>连续离散变量标注</p></li></ol><p>下面将object类型字段提取出来进行处理</p><p><code>tcc.select_dtypes("object").columns  #直接提取object类型字段</code></p><p>查看dataframe各列的取值</p><p><code>df.nunique() # 查看不同取值个数</code><code>df.unique()  # 查看取值</code></p><p>查看某列不同取值出现的次数</p><p><code>df["B"].explode().value_counts().to_dict()</code></p><ol start="4" type="1"><li>缺失值替换 法1： <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">tcc<span class="hljs-selector-attr">[<span class="hljs-string">&quot;totalcharges&quot;</span>]</span> = tcc<span class="hljs-selector-attr">[<span class="hljs-string">&quot;totalcharges&quot;</span>]</span><span class="hljs-selector-class">.apply</span>(lambda x: x <span class="hljs-keyword">if</span> x != <span class="hljs-string">&quot; &quot;</span> <span class="hljs-keyword">else</span> np.nan)<span class="hljs-selector-class">.astype</span>(<span class="hljs-attribute">float</span>)<br>tcc<span class="hljs-selector-attr">[<span class="hljs-string">&quot;totalcharges&quot;</span>]</span> = tcc<span class="hljs-selector-attr">[<span class="hljs-string">&quot;totalcharges&quot;</span>]</span><span class="hljs-selector-class">.astype</span>(<span class="hljs-attribute">float</span>)<br></code></pre></td></tr></table></figure> 法2： <figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">df1.TotalCharges = pd.<span class="hljs-keyword">to</span><span class="hljs-constructor">_numeric(<span class="hljs-params">df1</span>.TotalCharges, <span class="hljs-params">errors</span>=<span class="hljs-string">&quot;coerce&quot;</span>)</span> # <span class="hljs-string">&quot;coerce&quot;</span>表示无法转化的用缺失值填补<br></code></pre></td></tr></table></figure></li><li>异常值点检测</li></ol><h2 id="变量相关性探索与探索性分析">3 变量相关性探索与探索性分析</h2><h3 id="变量相关性分析">3.1变量相关性分析</h3><ol type="1"><li>标签处理</li></ol><p>对标签y进行处理</p><p><code>df3["churn"].replace(to_replace="Yes", value=1, inplace=True)</code><code>df3["churn"].replace(to_replace="No", value=0, inplace=True)</code>- 2.分类变量处理</p><p>转换为分类变量转化为哑变量</p><p><code>df_dummies = pd.get_dummies(df3)</code></p><ul><li>3.热力图展示相关性</li></ul><p>只能大概看看效果 <figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">plt</span><span class="hljs-selector-class">.figure</span>(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">200</span>)<br><span class="hljs-selector-tag">sns</span><span class="hljs-selector-class">.heatmap</span>(df_dummies.corr());<br><br><span class="hljs-selector-tag">df_dummies</span><span class="hljs-selector-class">.corr</span>()<span class="hljs-selector-attr">[<span class="hljs-string">&quot;Churn&quot;</span>]</span><span class="hljs-selector-class">.sort_values</span>(ascending=False)<span class="hljs-selector-class">.plot</span>(kind=<span class="hljs-string">&quot;bar&quot;</span>)<br></code></pre></td></tr></table></figure></p><h3 id="数据探索性分析">3.2数据探索性分析</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs routeros">fig,<span class="hljs-attribute">axes</span>=plt.subplots(nrows=1,ncols=2,figsize=(12,6), <span class="hljs-attribute">dpi</span>=100)<br><br><span class="hljs-comment"># 柱状图</span><br>plt.subplot(121)<br>sns.countplot(<span class="hljs-attribute">x</span>=<span class="hljs-string">&quot;gender&quot;</span>,hue=&quot;Churn&quot;,data=tcc,palette=&quot;Blues&quot;, <span class="hljs-attribute">dodge</span>=<span class="hljs-literal">True</span>)<br>plt.xlabel(<span class="hljs-string">&quot;Gender&quot;</span>)<br>plt.title(<span class="hljs-string">&quot;Churn by Gender&quot;</span>)<br><br><span class="hljs-comment"># 柱状堆叠图</span><br>plt.subplot(122)<br>sns.countplot(<span class="hljs-attribute">x</span>=<span class="hljs-string">&quot;gender&quot;</span>,hue=&quot;Churn&quot;,data=tcc,palette=&quot;Blues&quot;, <span class="hljs-attribute">dodge</span>=<span class="hljs-literal">False</span>)<br>plt.xlabel(<span class="hljs-string">&quot;Gender&quot;</span>)<br>plt.title(<span class="hljs-string">&quot;Churn by Gender&quot;</span>)<br></code></pre></td></tr></table></figure><p align="right">lucky</p><p align="right">时23年5月5日</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>特征工程</tag>
      
      <tag>案例</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>山科美景（毕业）</title>
    <link href="/2023/05/05/%E5%B1%B1%E7%A7%91%E7%BE%8E%E6%99%AF%EF%BC%88%E6%AF%95%E4%B8%9A%EF%BC%89/"/>
    <url>/2023/05/05/%E5%B1%B1%E7%A7%91%E7%BE%8E%E6%99%AF%EF%BC%88%E6%AF%95%E4%B8%9A%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h2 id="j9教学楼西北角">J9教学楼西北角</h2><p><img src="/images/shankemeijing2/640.jpeg" alt="梅花1"> <img src="/images/shankemeijing2/640-1.jpeg" alt="梅花2"> <img src="/images/shankemeijing2/640-2.jpeg" alt="梅花3"> <img src="/images/shankemeijing2/640-3.jpeg" alt="梅花4"></p><h2 id="玉兰大道j1教学楼沿道学生公寓c区各地">玉兰大道、J1教学楼沿道、学生公寓C区各地</h2><p><img src="/images/shankemeijing2/640-4.jpeg" alt="玉兰1"> <img src="/images/shankemeijing2/640-5.jpeg" alt="玉兰2"> <img src="/images/shankemeijing2/640-6.jpeg" alt="玉兰3"></p><h2 id="玉兰大道与j1教学楼沿道交叉处名人园西侧">玉兰大道与J1教学楼沿道交叉处、名人园西侧</h2><p><img src="/images/shankemeijing2/640-7.jpeg" alt="杏花1"> <img src="/images/shankemeijing2/640-8.jpeg" alt="杏花2"> <img src="/images/shankemeijing2/640-9.jpeg" alt="杏花3"> <img src="/images/shankemeijing2/640-10.jpeg" alt="杏花4"></p><h2 id="s5实验楼西侧墨水河沿岸">S5实验楼西侧、墨水河沿岸</h2><p><img src="/images/shankemeijing2/640-11.jpeg" alt="连翘1"> <img src="/images/shankemeijing2/640-12.jpeg" alt="连翘2"></p><h2 id="j1教学楼西侧校内快递服务中心旁">J1教学楼西侧、校内快递服务中心旁</h2><p><img src="/images/shankemeijing2/640-13.jpeg" alt="美人梅1"> <img src="/images/shankemeijing2/640-14.jpeg" alt="美人梅2"> <img src="/images/shankemeijing2/640-15.jpeg" alt="美人梅3"></p><h2 id="繁星广场学生公寓a区j1教学楼南沿道">繁星广场、学生公寓A区、J1教学楼南沿道</h2><p><img src="/images/shankemeijing2/640-16.jpeg" alt="紫叶李1"> <img src="/images/shankemeijing2/640-17.jpeg" alt="紫叶李2"> <img src="/images/shankemeijing2/640-18.jpeg" alt="紫叶李3"></p><h2 id="砚湖西南角c区沙排场东侧">砚湖西南角、C区沙排场东侧</h2><p><img src="/images/shankemeijing2/640-19.jpeg" alt="梨花1"> <img src="/images/shankemeijing2/640-20.jpeg" alt="梨花2"> <img src="/images/shankemeijing2/640-21.jpeg" alt="梨花3"> <img src="/images/shankemeijing2/640-22.jpeg" alt="梨花4"></p><h2 id="j1教学楼沿路染井吉野樱花">J1教学楼沿路（染井吉野樱花）</h2><p><img src="/images/shankemeijing2/640-23.jpeg" alt="樱花1"> <img src="/images/shankemeijing2/640-24.jpeg" alt="樱花2"> <img src="/images/shankemeijing2/640-25.jpeg" alt="樱花3"></p><h2 id="名人园北侧小亭子旁垂枝樱花">名人园北侧小亭子旁（垂枝樱花）</h2><p><img src="/images/shankemeijing2/640-26.jpeg" alt="樱花4"> <img src="/images/shankemeijing2/640-27.jpeg" alt="樱花5"></p><h2 id="夜晚的樱花">夜晚的樱花</h2><p><img src="/images/shankemeijing2/640-28.jpeg" alt="樱花6"> <img src="/images/shankemeijing2/640-29.jpeg" alt="樱花7"></p><h2 id="名人园西侧j3教学楼南水杉林下">名人园西侧、J3教学楼南水杉林下</h2><p><img src="/images/shankemeijing2/640-30.jpeg" alt="二月兰1"> <img src="/images/shankemeijing2/640-31.jpeg" alt="二月兰2"></p><h2 id="后勤管理处东侧学生公寓a区北侧北美海棠">后勤管理处东侧、学生公寓A区北侧（北美海棠）</h2><p><img src="/images/shankemeijing2/640-32.jpeg" alt="海棠1"> <img src="/images/shankemeijing2/640-33.jpeg" alt="海棠2"> <img src="/images/shankemeijing2/640-34.jpeg" alt="海棠3"> <img src="/images/shankemeijing2/640-35.jpeg" alt="海棠4"></p><p align="right">以上内容均摘自山东科技大学公众号《她们是！嵙大校花！》一文</p><p align="right">原文链接：https://mp.weixin.qq.com/s/50BA4cwEvN8T2YH7kkSEyA</p>]]></content>
    
    
    <categories>
      
      <category>风景</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Management Innovation</title>
    <link href="/2021/11/30/Management-innovation/"/>
    <url>/2021/11/30/Management-innovation/</url>
    
    <content type="html"><![CDATA[<p>  这篇文章是发表于《Academy of ManagementReview》的一篇关于管理创新的论文，我们老师让我们将其整理和展示作为课程作业，在这里记录一下当时做的总结（好像是第一轮，还很长，时间过得太久想不起来了），仅用作课堂展示。</p><h2 id="摘要">摘要</h2><p>我们将管理创新定义为一个创新实践（其结构、过程、技术都是最新的，并且想要达到一种更加有组织性的目标。采用一种组织内进化的观点（intraorganizationalevolutionaryperspective），我们考察了组织内外能够塑造和驱使组织的四个关键性变动：动机、发明、应用、实践和标记（theorizationand labeling），希望定义一个模型来反映出创新管理是如何产生的。</p><span id="more"></span><h2 id="文献综述">文献综述</h2><p>在过去的半个世纪，有大量的许多类型的关于创新的论文，大多数调查聚焦于从多个视角分析科技创新；在之后的15年里开始趋向研究创新的形式（例如过程创新，服务创新和战略创新），提供了一个视角来理解他们是怎样管理以及怎样长期的发挥作用支持一个企业成功。</p><h2 id="文章的写作目的和内容">文章的写作目的和内容</h2><p>这篇论文的侧重点在于调查创新的形式——并且尤其探索这个过程是如何产生的。我们应用一个和创新管理相近的定义——具体来说，管理实践、过程、结构、科技的发明和应用都是一个新的艺术并且是为达到更高的组织目标的存在的。虽然创新管理的许多里程碑对于商业学者来说都是很熟悉的。（例如以通用电气为代表的现代企业的发展还有通用汽车的M-形式的组织结构的发明），但他们对管理创新的知识量的应用是有限的。</p><p>从最广泛的角度上讲，在这些年里管理创新理所当然的受到了很多的重视。在下面的段落讨论中，本文主要有四个关键的观点：1.一个观点关注于社会经济条件，在这种条件下新的管理理念和管理实践开始塑造。2. 一个时尚的观点关注于使用者与提供者对动态实践。 3.一个文化的观点关注于一个组织对于一个新的管理实践是如何反应的。 4.一种理性的视角，关注于组织中的个人（管理者）是如何有效的将它运用到组织之中的。</p><p>还有一系列的相关文献涉及随后创新管理在国家和组织间的传播。但是虽然这些文章的主体是有用的，他们对于产生过程，包括新的管理理念第一次被创造和应用的描述出乎意料的少。与之不同的是，我们对于管理创新过程的理解十分有限并且都是基于一个大的众所周知的例子，例如Chandler的关于M-结构兴起的文献。在这片文献中我们提供了第一步——一个有系统的、全面的关于管理创新的理论过程。</p><p>我们关注于一些具体的在企业内部和外部的可能促使一个管理创新兴起的个人作用，我们管它叫管理创新，作为一种在这个过程中关键的捕捉人的潜在的能动作用的方式。我们定位两个具体的问题。第一，什么是管理创新？我们怎样以一种有用并且严密的方式定义管理创新，且能够强调其独特性。第二，并且在第一个问题的基础上，说明管理创新的产生过程以及它是怎样被提出的？在管理创新的产生中，对于个人在企业内外部的行为序列结果文献告诉了我们什么？我们能在多大的程度上归纳出一条对于管理创新产生的关于因果机制的基本论点。这篇文章包含对于管理创新的可能带来提前更深入的理解的思考。</p><h2 id="解决第一个问题什么是管理创新">解决第一个问题：什么是管理创新？</h2><p>管理创新包括在一个已建立的组织中引入新事物，从最广泛的意义上讲，管理创新可以定义为一个组织中管理活动的形式、质量或状态随时间的变化，这种变化是一种新颖的或前所未有的与过去的背离。基于这一高层次的定义，我们在文献中确定了四种不同的管理创新视角，如表1所示。这四种视角应被视为过去研究所围绕的主导视角，而不是从理论上全面研究所涵盖的领域。我们的方法在某种程度上借鉴了来自所有四个视角的见解，但与理性视角关系最为密切。</p><h3 id="管理创新的四个视角">管理创新的四个视角</h3><table><thead><tr class="header"><th style="text-align: center;">特征</th><th style="text-align: center;">制度视角</th><th style="text-align: center;">时尚视角</th><th style="text-align: center;">文化视角</th><th style="text-align: center;">理性视角</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">核心问题</td><td style="text-align: center;">对于管理创新而言什么样的制度条件导致了知识产权的产生和扩散</td><td style="text-align: center;">如何在供求方面提出新的管理思路影响管理创新过程？</td><td style="text-align: center;">管理创新是如何塑造组织内部的文化环境的？</td><td style="text-align: center;">管理者在创造和实施新的管理实践中扮演什么角色？</td></tr><tr class="even"><td style="text-align: center;">影响创新过程的关键影响因素</td><td style="text-align: center;">主要影响者群体的制度条件和态度</td><td style="text-align: center;">新思想的提供者及其提议的合法性</td><td style="text-align: center;">引入创新的组织文化</td><td style="text-align: center;">组织内外推动过程的关键个人的行动</td></tr><tr class="odd"><td style="text-align: center;">人的能动性在管理创新过程的推动作用</td><td style="text-align: center;">很少讨论</td><td style="text-align: center;">很少讨论</td><td style="text-align: center;">代理人很重要，但受到权利关系和传统的制约</td><td style="text-align: center;">代理在组织环境中产生并推动该流程</td></tr><tr class="even"><td style="text-align: center;">分析水平</td><td style="text-align: center;">公司+行业/国家</td><td style="text-align: center;">公司+新创意市场</td><td style="text-align: center;">公司+个人</td><td style="text-align: center;">公司+个人</td></tr><tr class="odd"><td style="text-align: center;">创新过程中的变革和结果</td><td style="text-align: center;">管理思想或实践的渐进性变化，有时通过更有效的方式发挥作用</td><td style="text-align: center;">炒作然后幻灭的循环结果，没有证据表明创新能够带来长期利益</td><td style="text-align: center;">社会建构的变革过程：通常很少通过改变工作方式和维持现有的工作关系</td><td style="text-align: center;">管理实践向更有效的工作方式逐步转变：不能保证成功</td></tr></tbody></table><p>制度观点的支持者采取宏观和边角的方法来理解特定管理创新出现的制度和社会经济条件</p><ul><li>吉尔（1994）：考察了七组制度因素对四个国家引入新的管理思想和技术的影响</li><li>Cole（1985）：着重研究了主要由国家制定的劳动力市场激励、行业协会的相对实力和有组织劳动力的倾向之间的平衡对不同国家引入小团体活动的影响。</li><li>Kossek(1987):考察了行业和企业层面对人力资源管理创新产生的影响，关于什么是进步的规范性信念可能会推动管理创新，但这些信念也会受到长期的康德拉蒂耶夫经济变革浪潮的影响，在这种变革中，新技术的出现会造成绩效差距，从而需要管理创新。</li></ul><p>制度视角衡量的是围绕特定意识形态的话语以及具体实践或技术层面的创新，他没有考虑人的能动性在形成过程中的作用；相反，他侧重于创新首先出现的先决条件，然后是使产业能够采用这种创新的因素。</p><p>时尚视角关注管理创新是如何通过使用新管理理念的管理者和提出这些理念的“时尚引领者”之间的动态互动而产生的（Abrahamson，1991，1996）。这一观点为管理时尚的形成提供了丰富的见解。-对购买这些时尚的管理者的典型属性的详细理解（Gill&amp;Whittle，1993；Huczynski，1993年；杰克逊，1986），- 时装设计师对他们的创意形成初期需求的方式（Benders和vanVeen，2001；克拉克，2004年；基泽，1997年；马扎和阿尔瓦雷斯，2000年）。然而，对于管理时尚的真正起源，以及为什么某些创新成为时尚它几乎没说。</p><p>时尚视角跨越了宏观和微观层面的分析，既关注提供新管理理念的行业，也关注个别管理者选择接受这些理念的行为原因。管理时尚可以作为抽象的思想或修辞，或作为具体的实践或技术而存在。</p><p>文化视角的支持者试图理解管理创新是如何形成并被实施该创新的组织的文化所塑造的。它通过观察个人对管理创新的态度如何与组织互动，在中观层次上分析创新的层次介绍。</p><p>这篇文献的一部分采用了批判的观点（Knights&amp;McCabe，2000；McCabe，2002），而另一种则采用组织内过程的观点（Stjernberg&amp;Philips，1993；Zbaracki，1998），但两者都有一些共同的主题：-认识到既定的组织不容易改变，管理创新既有修辞成分，也有技术成分，引入管理创新的结果很少是引入创新的高级管理人员的意图。</p><p>与前两种观点不同，文化观点提供了一些关于管理创新如何实施的见解，尽管主要是从被要求参与这一过程的人的角度，而不是从推动这一过程的人的角度。根据这一观点，管理创新的结果通常是对现状的强化（McCabe，2002）。这一观点并不否认管理创新会导致变革，但大型组织中的力量通常会削弱其影响。</p><p>理性的观点建立在这样一个前提之上：管理创新是由个人引入的，目的是使他们的组织更有效地工作。根据这一观点，一个人提出了一个创新的解决方案，以解决组织面临的一个具体问题，然后他或她支持该方案的实施和采用（Burgelman，1983；豪厄尔和希金斯，1990）。从这一角度进行的一些研究倾向于采用案例研究方法（例如，Chandler，1962；Tichy和Sandstrom，1974），而其他人则使用大样本定量方法（Damanpour，1987；Kimberly&amp;Evanisko，1981），但是所有的研究都是通过关注组织和环境背景下关键个人的行为来跨越微观层次的分析。在这一观点中，还有一个与管理和技术创新之间的联系有关的子主题，这表明它们可能共同作用（Damanpour&amp;Evan，1984；埃特莉，1988年；乔治扎斯和夏皮罗，1993）。</p><h3 id="管理创新的操作性定义">管理创新的操作性定义</h3><p>前面强调了研究人员用来理解管理创新现象的非常不同的方法，它有助于我们关注在我们寻求制定一个可操作的定义是出现的三个关键问题。1. 怎样定义“被创新”？（What exactly is beinginnovated?）这四个视角中的术语几乎没有一致性，但我们认为将两个层次的分析分开是有用的。在更抽象的层面上是管理思想，克莱默将其定义为“关于管理者应该做什么的相当稳定的知识体系...假设、公认原则和议事规则的体系”（1975:47）。管理思想的例子有科学管理（scientificmanagement）、全面质量管理(total quanlity management,TQM)和学习型组织(learningorganization)。虽然不完全相同，但这种管理理念的概念可与Guille（1994）的组织意识形态概念，以及大麦和昆达（1992）、亚伯拉罕（1996）、苏达比和格林伍德（2005）的管理修辞概念相提并论。在更具操作性的层面上，我们可以识别管理实践、管理过程、管理技术和组织结构。作为在组织内部完成工作的规则和惯例的不同方面（为了可读性，我们在本文的其余部分使用术语“管理实践”来涵盖这一系列活动）。从定义上讲，这篇文章侧重于运营层面的管理创新，即新实践、流程、结构的产生和实施，或者技术，因为这是在工作方式和管理创新过程中可以观察到的变化发生的水平。但是，很明显，新管理实践和新管理理念的发展之间存在着重要的相互作用，因此我们的理论论证将适当考虑这两个层次的分析。2.创新必须有多新？文献中有两种同样有效的观点。Abrahamson（1996）和Kimberly（1981）将创新定义为“最新技术”，这基本上意味着没有已知的先例。但是许多其他研究者含蓄地将创新视为“组织的新事物”，因此，例如，一个组织最初引入全面质量管理计划可能被归类为管理创新（例如，McCabe，2002；Zbaracki，1998年）。我们对本文感兴趣的是最新的最新技术创新，主要原因是这是现有知识最有限的领域。但是，这两个定义之间的界限是模糊的：如果一个组织考虑一系列实施管理实践的方法，在左侧，一个组织可能会从一家咨询公司购买一个“现成”的实践，在右侧，它可能会提出一个完全新颖的自己的创新。我们感兴趣的是那些朝着正确方向发展的创新，这些创新对创新组织的特定环境的适应程度很高，其结果存在相当程度的不确定性。3.管理创新的目的是什么？时尚和文化观点的支持者认为管理创新对组织没有什么持久的影响，而制度和理性观点的支持者认为管理创新为创新企业和/或整个社会产生积极的结果。如前所述，我们的重点与理性的观点最为直接，因为我们认为管理创新是为了促进组织的目标，这可能包括绩效的传统方面（如财务目标）和更软的方面（如员工满意度）。这是适当的，因为它有助于解释为什么企业准备在第一时间参与成本高昂、风险稍大的管理创新过程。这种方法强调了一个重要的观点，即并非所有的管理创新最终都是成功的。例如，沃尔沃多年来一直在进行单元制造的试验，其目的是提供显著的效益，但这种创新最终被中止（Berggren，1992）。此外，还应当指出，目标很少完全是本组织的外生目标；事实上，创新的过程可以导致引入新的实践或方案，最终改变组织的目标（Selznick，1957）。</p><p>总之，我们将管理创新定义为一种管理实践、过程、结构或技术的产生和实施，这种管理实践、过程、结构或技术是最新的，旨在促进组织目标的实现。虽然这不是我们定义的必要组成部分，但值得强调的是，我们对管理创新的观点有意识地关注推动这一过程的个人。事实上，本文的主题之一是需要在管理创新中增加对人的能动性的强调，同时不要忽视制度和时尚视角所关注的背景动态。正如麦卡贝所说，“需要的是理解创新是一个复杂得多的社会过程的一部分：与个人解释、行动和赋予世界意义的方式相关”（2002:509）。</p><h3 id="管理创新与相关结构">管理创新与相关结构</h3><p>在确立了管理创新的可操作性定义之后，我们还需要初步论证管理创新过程本身的理论探讨是必要的。</p><p>我们提出了使管理创新与众不同的三个关键因素。</p><ol type="1"><li>管理创新和技术创新的产出在性质上有着重要的区别，它们影响着各自过程的展开。管理创新在本质上通常是默契的，而且“即使不是不可能，也很难通过专利加以保护”（Teece，1980:464）；它们也相对“难以观察、界定和识别”（Alange等人，1998:8）。综上所述，与技术创新相比，这些属性允许潜在用户进行更高水平的主观解释，这反过来又增加了创新支持者所遵循的社会和政治过程的重要性。</li><li>很少有组织在管理创新领域拥有完善的专业知识。一个典型的大型组织可能会雇用数十或数百名具有技术创新技能的科学家，但如果有的话，很少有人具有经验证的管理创新技能（最接近的是组织发展顾问，他们寻求系统的方法来提高组织的整体效率和健康状况）。这种缺乏专业知识的情况既增加了整个组织人员管理创新的不确定性，也增加了对外部支持的需求。</li><li>新技术的引入给组织中的个人带来了模糊性和不确定性。含糊不清是因为对创新的预期价值缺乏理解，不确定性是因为担心创新会对个人和/或组织产生负面影响。如果提议的组织变革已经在其他地方成功实施（例如，安装新的IT系统），则其支持者可以通过引用以前的成功经验来消除个人的担忧，但如果变革是最新技术，那么，减少歧义和不确定性的任务就更难了。当然，所有类型的创新都会产生不确定性和模糊性，但它们对管理创新的影响可能更为深远，因为上面提到的其他属性。</li></ol><p>综上所述，这些属性表明，管理创新过程可能需要对组织的常规或DNA进行根本性的改变[4]（Argyris&amp;Scho1978年），这使得很难有效地进行，而且比组织变革的一般过程（变革对组织来说只是新的，而不是最先进的）或技术创新的过程（创新相对更有形，更少依赖于系统）要困难得多。这些因素反过来又突出了管理创新者寻求独特的方法来建立新实践的合法性的必要性，以使其为组织中的不同支持者所接受（Ashforth&amp;Gibbs，1990；Greenwood,Hinings和Suddaby，2002年；Suchman，1995年）。</p><ul><li>其中一种方法可能是更加重视外部来源的独立验证，以确定新实践的合法性，而不是一般性的组织变革活动（可以提到以前成功的变革）或技术创新（更有可能发生变革）客观效益和/或其签署的技术标准）。在没有确凿证据表明管理创新有价值的情况下，这种外部资源可以成为道德和认知合法性的有用提供者，并允许创新者“通过创造新的受众和新的合法化信仰来操纵环境结构”（Suchman，1995:587）。</li><li>第二种方法可能是创新者将精力集中在具有管理创新经验的组织（或组织内的特定单位）上，基于这些组织/单位了解管理创新者所面临的挑战，因此可能更能容忍其带来的不确定性和模糊性（Kossek，1989）。在寻求合法性的术语中，这可以被视为一种策略，即“在多种环境中进行选择，以追求支持当前实践的受众”（Suchman，1995:587）。简要地考虑一下管理创新和管理方式之间的区别也是有用的，即“一种相对短暂的集体信念，即一种管理技术（或理念）会导致理性的管理进步”（Abrahamson，1996:257）。在很大程度上，管理创新可以被认为是潜在的管理时尚：一些，如六西格玛和平衡计分卡，当它们被大量的管理时尚用户所采用时，就成为了管理时尚；其他公司要么消亡，要么继续在数量相对较少的公司中使用。但是，用高度抽象的术语表达的管理方式也有可能刺激管理创新。例如，20世纪90年代初的知识管理方式导致个人和组织采取具体做法，例如实践社区，这些做法本身就是管理创新。在讨论中，我们回到了管理创新与管理时尚的关系。</li></ul><figure><img src="https://note.youdao.com/yws/api/personal/file/WEBb69e5e7f12df2ee94ae957d88211c88f?method=download&amp;shareKey=3eb1560e918a863daa88691d3318a083" alt="image"><figcaption aria-hidden="true">image</figcaption></figure><figure><img src="https://note.youdao.com/yws/api/personal/file/WEB98d65a6ae1d40006d740ca6e0e373f0d?method=download&amp;shareKey=7dc54645939481943a6d675c1af28516" alt="image"><figcaption aria-hidden="true">image</figcaption></figure><h2 id="管理创新的过程">管理创新的过程</h2><p>本文的第二部分讨论了“管理创新产生的过程是什么？”基于我们对管理创新独特性的概念，我们开发了一个框架，突出了过程的四个相互关联的阶段以及两组关键利益相关者所扮演的角色。然后，利用管理文献中的理论论证和实例充实了这一框架。图1所示的框架有两个维度。横向维度包括创新过程的四个阶段：（1）动机是指促使个体考虑发展自己的管理创新的促进因素和促成环境(2）发明是一种最初的实验行为，从中产生了一种新的假设性管理实践(3）实施是在活体内（即在真实环境中）确定新管理创新价值的技术过程；（4）理论化和标签化是一个社会过程，组织内外的个体通过这个过程来理解和验证管理创新，从而建立其合法性。这四个阶段的过程建立在Burgelman（1991）和Zbaracki（1998）提出的企业内部进化观点的基础上，即环境（动机）的变化导致管理实践（发明）的变化，其中一些需要经过内部选择（实施）和保留（理论化和标记）。我们期望这一过程在很大程度上是由关键个人的有意识和有意识的行动形成的，但我们也认识到，个人的非预期行动和组织内部的随机变化在影响管理创新过程中起着一定的作用。根据图1中的纵向维度，我们期望两组个人来塑造这一过程：（1）内部变革代理人，他们是创新公司的员工，积极主动地创造兴趣、试验和验证相关的管理创新（DiMaggio，1988；Howell&amp;Higgins，1990）和（2）外部变革代理人，类似于Guille´n（1994）的管理知识分子和Abrahamson和Fairchild（2001）的创意企业家，是独立的顾问、学者和大师，积极主动地创造兴趣，影响新管理实践的发展，并使其有效性和保留合法化（DiMaggio，1991）。如前所述，我们期望外部变革动因在管理创新中发挥重要作用，因为它们在过程的许多不同阶段提供合法性和专业知识。他们可以使激发公司内部实验的最初想法具有可信度，他们可以在实施阶段与内部团队一起充当共鸣板或行动研究人员，他们可以在创新的理论化和标记方面发挥作用（Chandler，1962；卡普兰，1998年；佩泽特，1997年；Stjernberg&amp;Philips，1993年；约克斯和惠特塞特，1985）。这个框架的一个关键特性是它不假设简单的从左到右的活动序列。正如兹巴拉基所观察到的，创新的过程通常是复杂的、递归的，并且“在变异、选择和保留的嵌套和重复的循环中”（1998:612）。我们通过关注个体如何在框架中的相邻单元之间迭代来解决这一点，确定了十项核心活动。[5]例如，“问题驱动搜索”活动涉及内部变革主体在动机和发明之间来回迭代，鉴于“议程设置”活动涉及内部和外部变革动因之间的互动（参见Burgelman，1983，1991).图1确定了十项核心活动（由双箭头和横跨方框的文本表示）以及创新或其组成部分的性质（由每个方框内的编号文本表示）。图1还表明了环境在塑造管理创新中的重要作用。组织环境是管理层可以操纵的行政和社会机制，以塑造组织中行动者的行为（Bower，1970；Burgelman，1983），并将对内部变革动因进行与管理创新相关的核心活动的能力产生直接影响（正面或负面）。环境语境是一组广泛的刺激因素，这些刺激源于塑造管理话语的焦点组织（Guille）´n、1994年），从而影响外部变革动因与组织接触时的优先事项和努力。虽然这两个方面的背景可能会影响所有与管理创新相关的活动，但我们只在其角色至关重要的地方详细讨论它们。</p><h3 id="激励阶段">激励阶段</h3><p>激励阶段是指促使公司中的个人被激励去尝试新的管理创新的前提条件和促进因素。它解决了“在什么条件下，或者在什么情况下，高管们是否认为现有的管理实践不足以满足他们的需要？“对这个问题的回答远非直截了当，因为不仅有必要确定高管们寻求新的管理创新的条件，而且有必要具体说明他们选择不采用其中一种方法的情况以预制形式从所谓的管理时尚设置社区获得的现有解决方案（Abrahamson，1996）。换言之，要实现管理创新，管理时尚市场就必须失败。- 内部变革动因。首先考虑那些在“需求”方面的市场。已有的理论表明，对新的管理实践的需求是由一个新问题的识别驱动的，即组织当前和潜在绩效之间的感知不足[6]（大麦和昆达，1992；塞尔特和马奇，1963年；内疚´n、1994年）。感知到的不足可能是由破坏当前绩效的问题引起的，也可能是由可能存在的机会和对环境变化的预期引起的（Cyert&amp;March，1963；奥卡西奥，1997年）。在某些情况下，一个组织中的个别管理者可能会将这种不足仅仅归因于未能按照现有安排执行，但在另一些情况下，他们可能会针对其现有的管理实践发现一个特定的问题或机会。他们参与一个问题驱动的搜索过程，从现有的和接近的联系人开始，一旦找到满意的解决方案，他们就会终止搜索并实施解决方案。当个人选择在自己的组织之外寻找解决方案时，他们会面临一个管理时尚设置社区，这个社区塑造了用户关于什么是理性的信念体系，并兜售其针对用户问题或感知机会的特定解决方案。受遵守组织机构领域理性规范的压力和评估多个竞争性报价的成本的制约，管理者往往会选择采用似乎最为进步和合法的解决方案（Abrahamson，1996）。当然，这是管理时尚传播的过程。然而，有时，管理者会选择尝试开发自己的解决方案，以解决他们正在解决的问题或绩效不足。在制度理论的语言中，这样的行为可能会“显得不合理和倒退”（Abrahamson，1996:263），但当尝试新事物的压力克服了遵从外部仲裁的管理规范的压力时，这种行为可能会发生。我们提出两个这样的条件。首先，内部变革代理人能够通过议程设置活动来确定问题或机遇，从而使内部利益相关者将其视为真正的新问题或无法通过从时尚设置社区购买现有解决方案来解决的问题。以丹麦助听器制造商奥的康为例。当时的首席执行官LarsKolind能够说服他的员工和董事会，奥的康面临着来自大型竞争对手（如飞利浦和西门子）对其生存能力的重大威胁，这足以让他推动一项他称之为意大利面条组织（Foss，2003；Lovas和Ghoshal，2000年）。第二个广泛的条件是，组织环境支持新思维，从而提高内部变革主体追求新想法的自由度。支持性组织环境的概念在文献中有两个广泛的概念，这两个概念在这里都有潜在的相关性。其中一组论点集中于管理层在创造一个鼓励个人采取主动的非正式环境中的作用（Ghoshal&amp;Bartlett，1994）。例如，管理者对不同行业和组织的接触越多，他们就越容易接受新实践的想法（例如，Oldham&amp;Cummings，1996）。另一组论据则更关心本组织的正式程序，以及这些程序在多大程度上使寻求新的或更好的工作方式制度化。例如，我们可能期望组织中决策过程的严格性对内部变革动因的动机产生积极影响，因为通过澄清利弊，减少了与想法相关的不确定性和模糊性。</p><p>总而言之，内部变革主体通过与外部变革主体的对话来评估问题或机遇，这种对话有助于确定问题或机遇的新颖性，并参考当前变革的支持性组织背景。只要问题或机遇可以被界定为新颖的，而且背景是支持性的，管理创新的前提条件就存在。- 外部变革因素。外部变革推动者在激励管理创新方面的作用始于他们在商业环境中识别需要管理层关注的新威胁和机遇的能力。但是，如上所述，这只是故事的一部分，因为许多外部变革推动者认为他们的作用是激励管理者（通过议程设置过程）采用现有的或流行的做法，而不是创造新的做法。我们认为，外部变革主体与内部变革主体共享的管理知识的性质是激励管理创新的重要因素。人们可以识别一系列管理知识，在更抽象的方面有新的思想和想法，在更实际的方面有新的实践和技术。那些专注于实践的外部代理，为管理者面临的问题提供标准化或“现成”的解决方案，将鼓励采用管理方式。相比之下，那些专注于更抽象的领域的外部变革动因更有可能为管理创新提供一个肥沃的环境，因为他们的想法具有“解释的可行性”，即这些想法能够适应多种议程的程度（Benders&amp;vanVeen，2001；克拉克，2004）。</p><p>在议程设置中，外部变革动因可以直接或间接地与内部变革动因相互作用。7他们通过将他们对环境背景下的变革的解释与议程设置中有关高管面临的实际问题的对话联系起来，形成他们有影响力的观点。他们还受到先前参与的管理创新案例的影响；在图1中，这一反馈循环由三个水平过程（想法语境化、想法提炼和反思理论化）表示，我们将在下面更详细地讨论这些过程。</p><h3 id="发明阶段">发明阶段</h3><p>本发明涉及管理实践中随机或计划的变化，其中一些随后由该组织挑选和保留（Burgelman，1991年；坎贝尔，1965）。这是一个假设性的新实践首先以实验的方式进行试验的阶段。内部变革动因。图1显示了三种方式，在这些方式中，内部变革代理人可能会提出一个假设的新实践：问题驱动的搜索、尝试和错误，以及与外部变革代理人联系的想法。虽然这些子流程中的每一个都有其自身的价值，但我们的期望是，当它们结合应用时，发明的可能性更大，正如新技术通常通过现有想法和实践的新颖组合而产生一样（Hargadon，2003:65；科古特和赞德，1992年；熊彼特，1947）。问题驱动搜索是一种有意识的、经常有计划的活动，在这种活动中，个体寻求创建一种新的实践来应对特定的问题或机会（Cyert&amp;March，1963）。钱德勒（1962）对阿尔弗雷德·斯隆（AlfredSloan）引入M-form结构的描述表明了这一类型的过程：斯隆在1920年提出的变革是对五个独立企业合并所产生的复杂性的直接回应。正如斯隆本人所说，“我为通用汽车公司撰写了‘组织研究报告’，作为一战后公司扩张所产生的具体问题的可能解决方案”（斯隆，1963年：32).观念联系是指组织中的个人将外部变革动因提出的新观念与组织内部正在进行的实验工作联系起来。这种联系可以看作是相对不同的网络之间的一种中介形式（Granovetter，1973；他们可以通过鼓励个人广泛阅读、参加会议和其他网络活动来培养。例如，商学院教授罗伯特·卡普兰（RobertKaplan）通过与斯科维尔公司（Scovill Corporation）和约翰·迪尔公司（JohnDeere ComponentWorks）的高管在一次会议上就他们正在试验的新成本计量方法进行对话，提出了作业成本法的概念（Kaplan，1998:98）。卡普兰一直在发展他自己的想法，以克服现有成本计量系统的失败（想法背景化），斯科维尔和迪尔的高管们一直在自己的组织内进行试验（试错）。但作业成本法本身的诞生是在卡普兰和企业高管开始互动时出现的。最后，当一个新想法的反馈来自于在实践中的尝试，而不是来自于它解决了一个现有问题的程度，或者它与外部变革动因的想法的契合程度时，就会出现试错。我们可以期望尝试和错误是任何有效管理创新的重要组成部分（当与其他活动结合进行时），但也有可能尝试和错误是整个过程的意外或临时起点。例如，家具零售商宜家（IKEA）允许其客户在繁忙时间从仓库挑选自己的扁平包装产品，因为人员短缺，这种做法被证明非常有效（尽管在最初尝试时没有预见到这种做法），因此在其他商店迅速实施（Bartlett&amp;Nanda，1990）。新的实践可以通过这种类型的偶然事件出现，当现有的实践适应不同的情况时也可以出现（Czarniawska&amp;Sevo）´n、2005年；马曼，2002年；2004年）。外部变革因素。在发明阶段，外部变化剂的作用反映了内部变化剂的作用。换言之，他们提出管理实践新理念的能力取决于三个经常联系在一起的活动：理念语境化、理念提炼和理念联系。创意情境化包括对新的工作方式进行推测，以应对商业环境中潜在的威胁或机遇。这是管理思考者之间的一项常见活动，涉及到管理者面临的一方的无数问题与另一方的一系列可能解决方案之间的来回互动。例如，Davenport和Prusak（2003:179）描述了他们关于知识管理的最初想法是如何通过安永商业创新中心的研究议程产生的。想法提炼可以被视为一种有纪律的想象（Weick，1989），在这种想象中，外部变革动因通过一个特定想法在实践中或其他情境中如何运作的含义来发挥作用。坎贝尔（1974）认为这一活动是“观念上的试错”；它直接类似于内部变革主体所经历的试错过程，但它发生在概念领域。</p><p>如前所述，思想联系涉及协调外部变革动因的知识库（通常在学术纪律或职能专业知识方面较为深入）与内部变革动因的特定背景思想。例如，作业成本法是由于对现有会计方法的不满和卡普兰对制造业公司不断变化的压力的看法相结合而产生的，但它需要与斯科维尔和迪尔有明确的联系，这一概念才能付诸实施（卡普兰，1998年）。</p><p>综上所述，这三项活动可被视为理论发展的替代但互补的方法：思想语境化是指为现有问题开发新的解决方案，思想提炼是指通过一系列“思想试验”来解决思想的后果（Weick，1989），观念联系是一个归纳-演绎的循环，通过这个循环，概念与经验证据相协调。</p><h3 id="实施阶段">实施阶段</h3><p>实施阶段包括创新的“技术”方面的所有活动，从最初的实验到新的管理创新首次全面实施为止。与Zbaracki（1998）一样，我们区分了作品的技术元素和与创新理论化和标记相关的修辞元素（在下一节讨论）。我们对这一阶段的描述包括理解内部和外部变革动因在实施体内新实践中的行为，以及了解现有员工对其作出反应并影响其实施的方式（列文，1951年）。内部变革动因。图1显示了两个主要的活动，内部变化代理参与，因为他们试图实施体内新的做法。一种是试错法，即通过监督和调整原始概念来取得进展。例如，为了开发宝洁公司的“连接和开发”创新流程，其创始人拉里•休斯顿（LarryHuston）观察到，在他拥有一套行之有效的利用外部技术资源的方法之前，他已经进行了六年的实验（Birkinshaw、Crainer和Mol，2007）。另一项活动是反思性实验，在这种实验中，内部变革主体根据他们更广泛的经验来评估进展。例如，Stjernberg和Philips就此类个体如何最有效地发挥作用进行了以下观察：随着（创新）尝试的进行，他（内部变革代理人）需要能够从自己行为的后果中学习，并相应地改变这些行为。如果他有良好的反思能力（1993:1199），他将更有能力看到和学习如何管理变化和学习困境。组织环境在促进或抑制新思想的实施方面也起着重要作用。Zbaracki（1998）观察到，员工对实施新的管理实践的反应通常是消极的：他们很可能被创新所吓倒，特别是如果创新具有重要的技术成分，而且员工大多不知道其潜在的好处。但管理创新的文化视角表明，员工的反应也会因个人情况和所处的直接工作环境而异（Knights&amp;McCabe，2000）。因此，实施过程可能涉及内部变革代理人的谨慎操作，因为他们将工作重点放在组织中更易于变革的部分。正如有关技术创新的文献所描述的那样，这些策略包括在整个组织中寻求冷漠的通道，建立高级管理人员联盟来支持他们的想法，将创新视为机遇而不是威胁，获取个人无法控制的资源，并保持一种普遍坚韧和执着的态度（Howell&amp;Shea，2001；Rothwell等人，1974年；Wrapp，1967年）。作为一个整体，文献表明，执行通过辩证的过程（范德文和普尔，1995年）。内部变革代理人尝试提议的新实践，并根据最初的想法（尝试和错误）、其概念有效性（反思性实验）和其他员工的反应（即组织环境）评估其进展。新实践的某些方面可能被证明是行不通的，雇员的反应在某些情况下可能与正在推行的做法直接相反。但经过几次迭代后，往往会出现一种结果，即对立力量的综合（Knights&amp;McCabe，2000；Zbaracki，1998年）。在其他情况下，由组织环境的各个方面产生的内部阻力可能足够大，以至于实验性的新实践根本无法推进。外部变革因素。与其他阶段相比，外部变革推动者在实施阶段发挥的作用不那么明确。外部变革动因缺乏对重点组织的深入背景知识，以及对大多数内部变革动因面临的结果的责任感，因此他们很少在实际实施新理念方面发挥积极作用。然而，我们认为，他们可能发挥关键的间接作用，使管理创新的发生。外部改变剂的作用实质是创造一个思维实验（类似于生物学家在活体内试验新分子之前进行的体外实验）。外部变革推动者从他们以前的经验（反思性理论）和他们对特定概念领域（例如，一门学科或一项职能能力）的深刻知识中汲取经验，以磨砺他们的新想法（想法提炼），并基于获得的见解，他们试图影响和指导内部变革动因的实施工作（想法测试）。有一些证据表明这组活动在实践中是什么样子的。例如，Stjernberg和Philips（1993）强调了外部变革推动者作为促进者和传声筒的作用，Kaplan对他自己在这一领域的经历进行了深思熟虑的描述：在这个密切参与实施的过程中，行动研究者[即外部变革动因]不仅推进了概念背后的理论，而且成为了熟练的实践者。当公司在应用创新时遇到困难时，这种技能也使行动研究者能够区分理论上的局限性和糟糕的实施（1998:106）。正如卡普兰所建议的，这些活动可以被认为是一种行动研究的形式，其目的是“在实践环境本身中建立理论，并通过干预实验对其进行测试”（Argyris&amp;Scho¨n、1991:86）。就我们的框架而言，外部变革动因因此扮演着双重角色，在他或她关于管理思想世界中什么可能有意义的思想实验和在实践世界中实际运作的体内实施之间来回摆动。这种双重角色潜在地为两个世界提供了深刻的见解。然而，不幸的是，有证据表明，这类干预措施正在减少。而行动研究有着辉煌的过去（Emery&amp;Trist，1960；Lewin，1946），近几十年来，它已经失去了更多被动形式的研究，我们在讨论中回到这一点。</p><h3 id="理论化和标记阶段">理论化和标记阶段</h3><p>第四阶段产生了一种理论化的新实践，即在组织内保留和制度化的实践。如上所述，有效的实施显然是过程的一个必要部分，但管理创新的无形性和系统依赖性意味着实施的结果在几年内可能非常不明确（Teece，1980）。因此，我们期望一个成功的管理创新会有一个重要的修辞成分。主要的变革代理人将设法向组织内外的选民证明新的做法是合法的，尽管这种新做法（根据定义）与时装界久经考验的产品有所不同（Abrahamson，1996；Suchman，1995年）。我们认为这一阶段由两个相互关联的要素组成：理论化和标记化。理论化正在增加“通过在采纳者之间创造相似性的认知，并通过为将要采纳的实践提供理论依据，来扩大接受范围”（Greenwood等人，2002；斯特朗和迈耶，1993年；Suddaby&amp;Greenwood，2005年；托尔伯特和祖克，1996）。因此，在本文的上下文中，理论化首先是关于为组织的机会和正在实施的创新解决方案之间的联系建立逻辑基础，其次是关于用与组织内外的关键支持者产生共鸣的术语表达这种逻辑。标签化是指为所讨论的管理创新选择一个反映其理论化的名称。标签已被证明对管理实践的可接受性有显著影响（Eccles&amp;Nohria，1992；基泽，1997年）。内部变革动因。在这一阶段，内部变革推动者的主要作用是在组织的员工中建立创新的合法性。[7]以此来化解员工经常表现出来的对管理创新的普遍怀疑（Knights&amp;McCabe，2000），内部变革推动者通常会对新实践的价值进行理论分析，并以这样一种方式给新实践贴上标签：让员工看到它的潜在价值，同时也认为它符合组织的现行规范。换言之，结果是一种新的实践，这种实践是针对直接的组织环境进行理论化的（而外部变革动因则侧重于超越这种直接环境的理论化）。应用Suchman（1995）的三种基本合法性形式有助于澄清这里使用的方法。务实的合法性（吸引员工的自利计算）是通过展示创新价值的早期证据和减轻员工的担忧来实现的，但在实施的早期阶段，这种证据可能很难获得。道德合法性（通过与组织价值体系的一致性进行积极的规范性评估）是通过强调创新是如何建立在公司经历的先前变革的基础上和/或组织有尝试新想法的传统来实现的。最后，认知合法性（对与更大的信仰体系和受众日常生活的经验现实相吻合的创新的合理解释的发展）通过表明管理创新是组织面临的特定和新颖挑战的必要解决方案来追求（Tolbert&amp;Zucker，1986）。这种形式的内部聚焦理论和标签最好由内部变革代理人来执行，因为他们在员工中的现有可信度（Stjernberg&amp;Philips，1993）。它是通过反思性实验（根据内部变革动因更广泛的经验来解释新实践）和与外部变革动因联系的理论（通过直接与变革动因交谈、阅读变革动因的书籍或倾听变革动因的讲话）的结合来实现的。外部变革因素。外部变化因素在理论和标记阶段的作用是双重的。首先，他们在组织内部建立认知合法性方面发挥着重要作用，因为他们作为独立专家的身份意味着他们被引入组织，作为公司活动的演讲者，验证组织面临的挑战的重要性以及提议的创新作为应对挑战的有效性。这种形式的输入在图1中称为理论连接。外部变革动因在为组织边界之外的创新建立合法性方面也发挥着重要作用。这通常被组织认为是一项有价值的活动，因为大多数员工都对外界（通过客户和外部合作伙伴、朋友或媒体）如何看待他们的组织有一定程度的了解，因此，他们对创新的看法在某种程度上取决于外部选民对创新的看法。报纸和杂志等有影响力的媒体在其他方面也发挥了重要作用，使个别高管和组织的行为合法化（Deephouse，2000；马扎和阿尔瓦雷斯，2000年；麦克奎尔，1985年；Pollock&amp;Rindova，2003），我们希望他们在这里扮演一个重要的角色，作为一个间接的沟通渠道，通过这个渠道，员工对创新的态度得以形成。外部聚焦的理论化和标记过程涉及一系列不同于内部聚焦过程的挑战。外部支持者通常是管理知识分子，如其他组织的高级领导人、记者、顾问和学者（Guille、1994年）。这些个体比员工在更抽象的层面上运作（也就是说，他们可能会意识到这些差异的存在，为外部受众建立创新合法性的方法可能会有所不同。只有证明创新正在产生有价值的产出，才能在面对外部选民时实现务实的合法性。例如，宝洁公司声称，由于其连接和开发创新过程，该公司将外部创意产生的新产品比例提高到40%（Huston&amp;Sakkab，2006）。然而，由于我们已经讨论过的原因，在管理创新的早期阶段，这样的证据相对难以收集起来。道德合法性是通过在管理知识分子中寻求对创新的积极规范性评价来实现的，这可能涉及到展示创新在程序上如何与现有管理实践相一致（例如，六西格玛被定位为全面质量管理的继承者；Harry&amp;Schroeder，2000），或者它可能涉及到证明组织是一个具有创新记录的公认的高绩效组织。相比之下，认知合法性通常是通过将创新作为解决所有大型组织面临的一般挑战或问题的逻辑解决方案来实现的。用基泽的话说，“新原则的实施是不可避免的（由管理大师提出的），因为旧原则在面临威胁的危险时必然会失败”（1997:57）。这种方法类似于对员工认知合法性的追求，只是这里的论点将用更抽象或通用的术语来表达。外部变革主体通常通过与内部变革主体的长期互动（通过理念联系、思想测试和理论联系活动）以及自身的反思性理论，发展其对特定创新的知识。外部变革推动者具备将当代商业挑战的创新背景化的技能，以及与媒体组织的必要联系。应该看到，内部变革推动者还可以通过撰写文章或书籍以及在会议上发言，帮助与外部支持者建立管理创新的合法性。尽管他们可能缺乏外部变革推动者的理论化技能和个人网络，但他们通过对变革过程的个人拥护而拥有更大的可信度，这可能有助于确立创新的道德合法性。</p><h2 id="讨论未来研究的途径">讨论未来研究的途径</h2><p>在这里，我们认为，管理创新是管理领域的一个重要现象，其发生的生成机制（即管理创新过程）本身在理论上是有趣的，而且也相对缺乏了解。我们制定了一个框架，强调内部和外部变革动因在这一进程中的重要作用，以及这两类行动者相互作用的方式。我们的框架提出了一些重要的见解，并为进一步的研究开辟了一些有趣的角度。</p><h3 id="管理创新活动的排序">管理创新活动的排序</h3><p>我们首先观察到，管理创新的过程并不总是按照从激励到理论化和标记的线性序列进行的。例如，一个遭受过多“聪明话”困扰的组织（Pfeffer&amp;Sutton，2000）可能有一些在动机、理论化和标记方面进展良好的计划，但在发明和实施方面没有相应的投资。在这种情况下，适当的管理干预可能是将注意力集中在执行上，以此确定哪些举措值得推行，而其他组织环境可能需要不同的干预措施。然而，目前我们对不同活动顺序的相对有效性知之甚少，这使得我们很难就如何提高干预措施的质量向管理人员提供任何一致的建议。我们的框架侧重于表1中相邻单元格之间发生的“活动”，如试错，以此强调创新是一个迭代过程。但是，要理解管理创新的整个过程，下一个重要的步骤将是检查活动随时间推移的实际顺序和阶段。有些创新可能遵循从左到右的线性活动顺序，而有些则不然；例如，宝洁公司的连接和开发计划是由其倡导者拉里•休斯顿（LarryHuston）提出的一个概念，早在公司首席执行官明确表示需要之前（Birkinshaw等人，2007年）。同样，虽然我们预计大多数管理创新主要由内部变革动因发起，但也有可能确定其他创新，如T-集团（Benne，1964；Blake，1995），其中许多核心活动都是由外部变革动因推动的。未来的研究应该尝试绘制出实际发生的序列，并使其有意义。在这方面，历史记录并不是特别有用，因为作者通常会将自己的结构强加给一个过程，以便理解它。因此，需要对当代案例进行研究，在可能的情况下，应实时跟踪这些案例，以避免出现回顾性感官偏见的问题。</p><h3 id="内部和外部动因的作用">内部和外部动因的作用</h3><p>我们框架的另一个核心要素是区分内部和外部变革动因。作为一个定义，内部变革代理人是重点组织的雇员，而外部变革代理人不是，这反过来意味着，内部变革代理人通常在组织内部拥有卓越的知识和网络，在交付成果方面比外部变革代理人更负责任。然而，对未来的研究来说，更仔细地考虑这一区别是很重要的，因为它在实践中可能并不总是明确的。例如，在变革过程中，顾问有时会被借调到他们的客户公司，而民族志研究人员往往会成为他们正在学习的组织中相当长一段时间的雇员。在这两种情况下，这些外部行为体实际上都会暂时成为内部行为体。此外，有证据表明，一些人能够在单个项目期间在内部和外部变革动因角色之间来回转换（即作为行动研究人员），而其他人则在职业生涯中在这两个角色之间摇摆（Davenport&amp;Prusak，2003）。因此，进一步研究的一个途径是仔细研究参与管理创新的关键变革动因，以及它们能够在多大程度上承担内部/外部混合角色。第二个问题可能是考虑内部和外部变革动因协调行动的程度。在这里，我们假设双方都有一个或多或少的共同目标，即实施成功的管理创新。然而，未来的研究可能希望放宽这一假设，并考虑两党真正结盟的程度。例如，在试图在内部和外部支持者之间建立管理创新的合法性时，内部变革代理人可能会淡化对其同事所要求的变革规模（可能通过强调与先前规范的一致性或低风险），以使变革更容易接受，而外部变革推动者可能会夸大拟议创新的规模（或许是将其定位为行业剧烈变革的解毒剂），以此作为在外部受众中产生兴趣的一种方式。这些定位上的差异可能会对相关人员以及创新的长期成功产生有害影响。未来研究的第三个途径，也是建立在内部和外部区别的基础上，就是研究管理创新的轨迹。我们的框架假设，确定一个新的管理实践首先在哪个组织实施是可能的，也是有意义的。虽然这种方法与我们提到的现有案例相比是有效的，但在将来可能会有不太有效的案例。越来越多的经济活动通过非企业网络（如开放源码软件社区）进行，因此我们可以期待创新的组织方式出现，从而实现这种类型的非企业协调。在未来，更多的管理创新也有可能（尽管可能性较小）在体外出现，也许是通过学术界的努力，而不是实践管理者的反复试验，在这种情况下，创新的中心也不会是组织。因此，未来的研究应仔细注意研究管理创新的分析单位，因为有几种可能的模式可以遵循。</p><h3 id="管理创新与管理时尚">管理创新与管理时尚</h3><p>我们认为，当时尚市场失灵时，即当一个组织追求自己的新颖实践而不是时尚界建议的实践时，就会触发管理创新过程。然而，这一论点掩盖了重要的一点，即在许多方面，管理时尚过程与管理创新过程有着重要的相似之处：两者都涉及到内部变革动因（Abrahamson[1996]称之为管理时尚的“用户”）和外部变革动因（管理时尚的“供应商”）的重要角色，以及两者之间的复杂互动。两者都可以用进化论的语言来描述，在组织中引入一些新的东西，这些东西随后被选择和保留，或者不被选择。因此，未来研究的一个有用方向将是更仔细地研究管理创新和管理时尚的过程是如何相互作用的。例如，可以通过抑制重点组织所选解决方案中的新颖性水平（例如，将自己的解决方案推离搁置的解决方案）来确定外部变革因素（如顾问）影响管理创新出现的方式，不管用户的议程）或通过加强议程（例如，鼓励用户制定自己的议程，并提出具有解释可行性的想法）。另一种方法可能是研究管理创新被时尚界接受并转变为管理时尚的条件。在抽象的层面上，此类实践可能具有高度“进步”和当代的标签（Abrahamson，1996），并且可能表现出高度的外部变革动因参与，但对于这些条件的详细情况，仍有更高层次的明确空间。</p><h3 id="管理创新与企业绩效">管理创新与企业绩效</h3><p>虽然我们在本文中主要关注的是流程问题，但关于个人为什么参与管理创新以及管理创新在多大程度上帮助组织实现其目标的问题同样重要。例如，某些管理创新似乎比其他创新更有可能提供竞争优势，这取决于它们的价值、稀有性和难以模仿的程度（Barney，1991），但这一论点仍有待实证检验。管理创新的后果是复杂的，因为许多不同的利益相关者都可能受到影响。有必要至少分离出三组不同的结果：（1）管理创新对创新企业内部各种绩效指标的影响（2）对创新后续采用者的绩效和合法性的影响；（3）管理创新对整个社会的好处，包括提高生产力或工作生活质量。如前所述，已经有一些关于其中第二个的研究（例如，Staw&amp;Epstein，2000），但是第一个和第三个基本上还没有被探索。因此，未来的研究可能会探讨为什么某些类型的管理创新比其他类型的管理创新要花更长的时间才能产生红利，一些管理创新是否会引发相关创新的浪潮，以及管理创新创造企业特定竞争优势的频率和情况。</p><h3 id="学术界在管理创新中的作用">学术界在管理创新中的作用</h3><p>最后，本文对学术界在管理创新过程中的作用提出了一些初步的思考。像亚伯拉罕和费尔柴尔德（2001）一样，我们担心学术界在影响实践的能力方面可能会输给时尚界的其他成员，如顾问和大师。我们的框架提出了一些可能的前进方向。一是让学术界在开发组织可能付诸实践的新思想和思想实验方面更具创造性。另一种方法是更多地参与我们称之为“想法测试”的活动，通过这种活动，学者与重点组织密切接触，并将他或她的见解带到组织正在解决的特定问题上。参与式奖学金的概念（VandeVen&amp;Johnson，2006）由来已久，但作为一种有效的奖学金形式，其合法性在近几十年来有所动摇。另一个选择是一个管理创新实验室，比如伦敦商学院的MLab，研究人员和实践者一起合作开发新的实践。这些建议需要进一步探讨，既要考虑到它们将需要的干预措施的性质，又要考虑到它们将取得的成果。他们还挑战了许多传统的正统的专业，因为他们很可能涉及新的方法，是未经证实和难以实施。但我们相信他们值得追求。管理学者在管理创新过程中发挥更积极的作用，将对创新组织有价值，并使他们能够重新发挥其作为新的和有用的管理知识创造者的作用。</p>]]></content>
    
    
    <categories>
      
      <category>工商管理专业英语</category>
      
      <category>课程作业</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工商管理专业英语</tag>
      
      <tag>论文</tag>
      
      <tag>学习</tag>
      
      <tag>课程作业</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>新型电子商务——参与者行为  第二章</title>
    <link href="/2021/10/01/%E6%96%B0%E5%9E%8B%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1%E2%80%94%E2%80%94%E5%8F%82%E4%B8%8E%E8%80%85%E8%A1%8C%E4%B8%BA-%E7%AC%AC%E4%BA%8C%E7%AB%A0/"/>
    <url>/2021/10/01/%E6%96%B0%E5%9E%8B%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1%E2%80%94%E2%80%94%E5%8F%82%E4%B8%8E%E8%80%85%E8%A1%8C%E4%B8%BA-%E7%AC%AC%E4%BA%8C%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h2 id="信息技术采纳购买与营销">2.1 信息技术采纳、购买与营销</h2><h3 id="研究背景">2.1.1 研究背景</h3><p>  现有研究基本都关注的是用户感知对信息技术采纳或持续采纳的意图和行为的影响效果。<span id="more"></span>  研究证实，用户感知和态度是影响用户做出创新采纳决策的前置因素。然而，在大部分个人层面的信息技术采纳研究模型中，用户感知直接作为自变量，很少有研究考虑用户如何获取信息技术的相关信息，以及这个信息对用户形成信息技术感知的影响。</p><p>  在大部分的采纳研究中，对用户感知的操控隐含在研究数据收集的过程中，感知形成的机制并没有在采纳研究中明确的体现。</p><h3 id="研究内容">2.1.2 研究内容</h3><p>本章将针对免费试用营销策略进行分析，研究用户信息技术的采纳决策。</p><h3 id="营销的免费试用策略">2.1.3 营销的免费试用策略</h3><p>  在免费使用策略下，用户有两个阶段的决策（决定接受免费试用，以及决定购买试用）</p><p>其中决定是否接受免费试用这个阶段的决策可以直接利用现有的采纳模型进行解释；而在试用完后决定是否购买以继续使用的行为则需要用到持续采纳研究的相关理论并考虑费用因素。</p><h2 id="研究的理论基础">2.2 研究的理论基础</h2><h3 id="实际使用前后的个人感知">2.2.1 实际使用前后的个人感知</h3><p>  个人感知一直以来都被用做研究信息技术的采纳以及持续采纳行为。</p><p>  信息技术采纳模型（TAM）中指出感知有用性和感知易用性是影响用户采纳意图形成的两个主要的因素，他们或对采纳意图直接影响，或先通过影响用户对信息技术的态度再间接影响采纳意图。</p><p>  Van der Heijden对TAM模型中的用户感知进行了扩展，指出感知娱乐性对与享乐型的信息系统的采纳行为有显著影响。感知有用性、感知易用性和感知娱乐性对于信息系统采纳行为的影响作用已经被大量、多领域的信息技术应用的采纳研究所证实。</p><p>  认知不协调理论：当人们的认知和实际不协调（不一致）时，人的认识行为将随之进行改变。就是说当人们在使用信息技术的过程中逐渐获得一手的关于信息技术使用的信息时，他们会将这种实际使用经验与未使用前形成的信息技术的初始感知进行比较，进而对个人信息技术的感知进行调整来减小这种不一致。</p><p>  由认知不协调理论发展而来的期望确认理论被用来研究信息技术的持续采纳行为，从而得到了信息技术持续采纳的期望确认模型（ECM），该模型已经被广泛用来研究信息技术的持续采纳行为。</p><h3 id="产品试用形式的营销手段">2.2.2 产品试用形式的营销手段</h3><p>  营销学以及消费心理学的研究者对于消费者的采纳行为的研究是通过探索消费者对于营销措施的反映来进行的。这些方面的研究结果证实产品试用过程中，消费者能够真正获得产品，进而通过视觉、嗅觉、触觉、听觉甚至是味觉等感官去体验产品，对于感官反馈的信息进行整理组合从而形成对产品和品牌的认知。免费试用开始被广泛采用并成为产品营销的重要手段。</p><p>  Smith和Swinyard的关于产品试用和广告效用的对比研究表明，从产品试用中获得的经验比广告对消费者感知形成的影响更深，从而使消费者在试用后对产品的态度更明确，态度和行为的一致性也更强。产品试用也会影响消费者的期望、需求和心理价位。</p><h3 id="信息技术采纳研究中的成本因素">2.2.3信息技术采纳研究中的成本因素</h3><p>  第二章整理了2000-2006年发表在IS领域知名期刊和会议上的信息技术采纳研究的整理发现，大部分的信息技术采纳研究都是采用TAM模型。</p><p>  TAM模型最初是用来解释组织中的信息技术行为，通过分析解释现有的使用行为，从而预测将来电脑工具的使用情况（如文字处理程序、电子邮件和软件开发工具）。组织在各种电脑工具上进行投资，而这些投资的回报主要是通过组织成员使用这些工具进行作业，完成工作任务来实现。而这些信息技术通常是由组织承担成本。</p><p>  随着信息技术的发展，开始出现收费的信息服务。本篇文章就针对免费信息技术和收费信息技术提出了一个考虑营销策略对于信息技术感知的影响，于是，第二章提出了一个考虑营销策略对于消费决策过程的影响的消费者对于收费信息技术的购买决策行为的研究框架。</p><h2 id="研究模型和假设">2.3 研究模型和假设</h2><h3 id="基于信息渗透理论分析产品试用">2.3.1基于信息渗透理论分析产品试用</h3><p>  基于信息渗透理论的研究表明，信息内容以及信息来源对新信息技术个人感知的形成有决定性作用，并且会进一步影响新信息技术的采纳决策。产品试用作为一种有效地将新信息技术展示给用户的营销策略，已经被证实对产品和品牌的认知和态度有显著影响。为了促进用户对收费信息技术的采纳，很多公司都开始采用免费试用的形式来帮助消费者在作出购买决策之前先了解产品的相关信息。</p><h3 id="基于消费者行为研究和认知不协调理论分析采纳行为">2.3.2基于消费者行为研究和认知不协调理论分析采纳行为</h3><p>  产品试用可以说是消费者对一个品牌或产品第一次的使用经验，使用是经验取得的一个主要来源。根据消费者行为研究和认知不协调理论，试用经验可以改变一个人对产品的感知、态度以及需求，因此，消费者在使用后对产品的认知可能会与最初采纳该产品时对产品的认知不同。KarahannaStraub 和 Chervany关于使用前后个人感知的对比研究表明，使用前后感知的形成因素是不一样的。使用前的感知形成主要来自间接经历（使用其他信息技术的经验，别人使用后的新的体会等），而使用后的感知形成主要来自直接的使用经历。Bhattacherjee和Premkumar的研究表明，人们对于信息技术创新的感知、态度、意图和使用等会随着人们对信息系统的使用而发生改变，人们在使用中不断学习，进而不断调整。试用营销策略中的试用后决定购买产品这种行为可以被看作是使用后的采纳行为（也就是持续采纳行为），而最初的决定接受试用的行为可以看做是最初的采纳行为。</p><h3 id="基于期望确认理论分析持续采纳行为">2.3.3基于期望确认理论分析持续采纳行为</h3><p>  Bhattacherjee提出用期望确认理论来研究信息技术的持续采纳行为，因为期望确认理论在一定程度上解释了使用经验改变人们认知和行为的机制。期望确认理论指出，用户将根据自己从实际使用信息系统中获得的经验而不断更新自己对信息系统的认知。再考虑了实际使用经验之后，人们的感知与没有实际使用经验时的感知就不同了，这些感知直接或间接地影响着人们对于信息技术的满意程度，从而影响人们持续使用该信息技术的意图。收费信息技术采用免费试用的策略，用户则可以通过接受免费试用获得信息技术使用的经验，进而对这种试用进行评价以形成试用后的感知和态度，以及对最终是否为这种信息技术付费以继续使用这个信息技术做出决策。这跟信息技术的持续采纳有相似之处，因此期望确认模型将被用来作为研究的理论基础</p><figure><img src="/images/新兴电子商务/新兴电子商务_2_1.png" alt="研究模型框架"><figcaption aria-hidden="true">研究模型框架</figcaption></figure><p><strong>本文为对于《新型电子商务——参与者行为》内容的一些整理，仅供自身学习使用。</strong></p>]]></content>
    
    
    <categories>
      
      <category>阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>从免费使用到产品采纳和购买</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>新型电子商务——参与者行为 第一章</title>
    <link href="/2021/10/01/%E6%96%B0%E5%9E%8B%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1%E2%80%94%E2%80%94%E5%8F%82%E4%B8%8E%E8%80%85%E8%A1%8C%E4%B8%BA-%E7%AC%AC%E4%B8%80%E7%AB%A0/"/>
    <url>/2021/10/01/%E6%96%B0%E5%9E%8B%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1%E2%80%94%E2%80%94%E5%8F%82%E4%B8%8E%E8%80%85%E8%A1%8C%E4%B8%BA-%E7%AC%AC%E4%B8%80%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="主要内容">1.主要内容</h1><p>  这一部分主要叙述4个方面</p><p>1.新型电子商务当前的发展状况</p><p>2.参与者行为 <span id="more"></span></p><p>3.国内外的研究发展情况</p><p>4.本书涵盖的5个方面</p><hr><h1 id="介绍">2.介绍</h1><h2 id="电子商务当前的发展状况">2.1 电子商务当前的发展状况</h2><p>  在经济一体化以及技术大融合的环境下，新型电子商务的经营模式以及运作激励产生了内生性的变化，并呈现出移动（泛在）性、虚拟性、极端数据、个性化以及社会性等鲜明的新特征，对于新型电子商务多元化、纵深化的研究势在必行。</p><h2 id="电子商务参与者行为">2.2 电子商务参与者行为</h2><p>  作为电子商务活动的基本单位，参与者的行为特征对于理解电子商务系统的运行、发展和演变规律具有基础性的意义。</p><p>提出以下几个问题：</p><ol type="1"><li><p>在移动商务条件下，消费者搜索、购买、浏览产品与服务的行为与传统电子商务条件下有何不同？</p></li><li><p>在交易实体、交易对象和交易过程全面虚拟化的环境中（例如在网络游戏中），参与者如何建立相互之间的信任并形成交易信誉？</p></li><li><p>在注重个性化的条件下，新的技术和服务如何才能被具有不同特点的用户所接受，并且在高度多样化的人群中扩散渗透？</p></li><li><p>在高度社会化的网络环境中，商务活动的价值产生方式与实体商务环境和传统电子商务环境有何不同？等等</p></li></ol><h2 id="国内外电子商务研究发展情况">2.3 国内外电子商务研究发展情况</h2><p>  国内外对电子商务参与者行为的研究大体上沿着4个主要的方向展开。一是围绕网络消费者的行为动机，分析搜索、浏览和购买的行为模式、影响因素和效用机理；二是围绕参与者的信誉，分析影响交易双方信誉的因素，进而建立灵活、健壮、平稳、可预测的在线信誉系统；三是围绕潜在用户对电子商务的采纳和接受过程以及在用户群体中的扩散规律，探讨用户的认知和行为模式影响这些模式的关键因素，从而更好的识别用户价值的产生机理；四是围绕创造竞争优势，研究电子商务价值产生的机理和价值评价方法。</p><h2 id="本书涵盖的5个方面">2.4 本书涵盖的5个方面</h2><h3 id="新型电子商务环境下的用户体验与激励机制">2.4.1新型电子商务环境下的用户体验与激励机制</h3><p>  2，3章从产品采纳和购买的视角，提出了基于用户感知的体验模型，并基于此分析了新型环境中免费试用等策略对于用户体验和购买行为的作用，同时着重探讨了用户推介激励机制中的用户心理感受与行为特征</p><h3 id="中国文化背景下的新兴信息系统采纳">2.4.2中国文化背景下的新兴信息系统采纳</h3><p>  第4章着眼于中国文化背景，力图从文化视角探讨新型电子商务及新兴信息系统的用户采纳行为。作为一种典型的东方文化，中国文化具有权利距离大、注重群体价值的特点，并强调“和谐”观念。这些文化特点对于新兴电子商务参与者的行为模式也可能具有独特的文化色彩。对于这种行为模式特点的认识和理解，将有助于中国的电子商务时间产生更多具有中国特色的创新。文化视角另一方面的含义在于，网络和电子商务的网络和电子商务的广泛普及，有可能进一步促进不同文化类型的融合。</p><p>  引入根植于东方文化价值的新因素将建造或拓展信息技术/系统使用者行为模型，以便更好地反映信息技术/系统在这些特殊环境中的实践。基于此，本书的研究工作着眼于从中国文化的角度，建立了考察使用者对于新技术使用态度的概念模型。</p><h3 id="社会化应用于企业市场的相互影响">2.4.3社会化应用于企业、市场的相互影响</h3><p>  本书第5、6章分别针对社会化应用在电子商务平台用户行为、企业内部员工行为特征与社会资本结构、金融市场信息环境特点等方面的作用与影响展开探讨。</p><h3 id="面向服务的消费者价值创造">2.4.4 面向服务的消费者价值创造</h3><p>  从产品导向的模式向服务导向模式的转型是当今商务业态发展的潮流所在。本书第7章力图通过消费者和企业的双重视角，在实体和在线零售渠道整合的维度阐明消费者价值创造的过程，以及基于IT的零售渠道整合能力和跨渠道人力资源能力对企业绩效的影响。</p><h3 id="新型电子商务环境中的外包政策">2.4.5新型电子商务环境中的外包政策</h3><p>  第8章针对服务外包中的这些不完全信息，运用委托代理理论和实物期权理论，研究了在不完全信息下如何设计有效的IT服务外包合同来缓解外包风险，实现外包成功。</p>]]></content>
    
    
    <categories>
      
      <category>阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>引言</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>新兴电子商务</title>
    <link href="/2021/10/01/%E6%96%B0%E5%85%B4%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1/"/>
    <url>/2021/10/01/%E6%96%B0%E5%85%B4%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="抱歉">抱歉</h2><p>之前想着写《统计学习方法》那本书的，结果一直拖着，老是也弄不好敲数学公式，再加上时间也紧，数学理论进一步整理对我现阶段的学习确实帮助不大，所以只能先放下，等过段时间闲下来再去做这件事情。<span id="more"></span> ### 为什么要整理这本书那时候我刚上大一，在图书馆找到其中一本，当时上面的公式、理论、方法对我一个大一的小菜鸟来说实在太难，我硬着头皮读了20多页（好像）就放弃了，并下定决心：两年以后我会回来的！到那时我一定能看懂这本书，于是就有了这次的整理。</p><h3 id="重读感受">重读感受</h3><p>两年之后再次读这本书，说实话我依旧对里面很多的东西有所欠缺，而这些欠缺也是我在现阶段论文写作所欠缺的知识，书中广泛的理论和方法使我感觉受益颇多.</p><h3 id="关于这次整理的安排">关于这次整理的安排</h3>这本书每一章就是一篇论文，所以打算按章来整理，每本书做一个汇总，本来是想每周整理一章的，但是算了一下这样一学期也整不了多少，所以暂定计划是一周整理两章，但是在保证数学复习进度的情况之下（马上要考试了，这次要好好弄），正好趁着国庆三天假期多整一点，也算是为之后分担压力了。<p align="right">国庆小记</p><p align="right">——lucky</p>]]></content>
    
    
    <categories>
      
      <category>阅读</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>source ~/.zshrc时报错，:9: bad assignment</title>
    <link href="/2021/04/13/source-zshrc%E6%97%B6%E6%8A%A5%E9%94%99%EF%BC%8C-9-bad-assignment/"/>
    <url>/2021/04/13/source-zshrc%E6%97%B6%E6%8A%A5%E9%94%99%EF%BC%8C-9-bad-assignment/</url>
    
    <content type="html"><![CDATA[今天又遇到问题了，运行source ~/.zshrc 时报错， <img src="https://note.youdao.com/yws/api/personal/file/WEBd301452106bfbcbe7bde816753a1a3bb?method=download&amp;shareKey=caa427e9b213a88ee7a387765f3cfeb7" alt="image"> <span id="more"></span>去一查，原来是shell中带有了空格，将空格删掉就行了，我的是等号周围加上了空格，因此报错，将空格删掉就行了！在<code>source ~/.zshrc</code>就成功了<p align="right">四月十三日</p><p align="right">lucky</p>]]></content>
    
    
    <categories>
      
      <category>问题解决</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>校园风光</title>
    <link href="/2021/04/08/%E6%A0%A1%E5%9B%AD%E9%A3%8E%E5%85%89/"/>
    <url>/2021/04/08/%E6%A0%A1%E5%9B%AD%E9%A3%8E%E5%85%89/</url>
    
    <content type="html"><![CDATA[<p>大学校园中的春天 <span id="more"></span></p><h1 id="山科之美舍友拍的">山科之美（舍友拍的）</h1><p><img src="/images/school/school_1.png"></p><p><img src="/images/school/school_2.png"></p><p><img src="/images/school/school_3.png"></p><p><img src="/images/school/school_3.png"></p><p><img src="/images/school/school_4.png"></p><p><img src="/images/school/school_5.png"></p><p><img src="/images/school/school_6.png"></p><p><img src="/images/school/school_7.png"></p><p><img src="/images/school/school_8.png"></p><p><img src="/images/school/school_9.png"></p><p><img src="/images/school/school_10.png"></p><p align="right">时2020年四月八日</p><p align="right">——lucky</p>]]></content>
    
    
    <categories>
      
      <category>风景</category>
      
    </categories>
    
    
    <tags>
      
      <tag>校园美景</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>有道云笔记插入图片</title>
    <link href="/2021/04/07/%E6%9C%89%E9%81%93%E4%BA%91%E7%AC%94%E8%AE%B0%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87/"/>
    <url>/2021/04/07/%E6%9C%89%E9%81%93%E4%BA%91%E7%AC%94%E8%AE%B0%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87/</url>
    
    <content type="html"><![CDATA[<p>平常经常用有道云笔记这个软件做笔记，我感觉用着还算不错，在怎么插入图片上查了好些方法，都显示不出来，偶尔翻到一个，突然解决了，在此简单记录<span id="more"></span> 首先，你要把新建一个文件夹，把图片放到里面。 <img src="https://note.youdao.com/yws/api/personal/file/WEBfe7d0f50bf5edf2288a0812264a01c70?method=download&amp;shareKey=94bf5b4273a390fc09ef14ce34439043" alt="image"> 然后分享 <img src="https://note.youdao.com/yws/api/personal/file/WEBc9a25d09d2b2a719d32b450c67027199?method=download&amp;shareKey=f3c70ead5fc523397dade3c906225333" alt="image2"> 复制链接 <img src="https://note.youdao.com/yws/api/personal/file/WEB92fc45f4a41894039479e7e0164f54fb?method=download&amp;shareKey=6c9cffd44b504b0dd8de29cabf2d405b" alt="image3"> 到浏览器上打开,复制链接 <img src="https://note.youdao.com/yws/api/personal/file/WEBd43706e509bcbf94d3b2280ef47a31ee?method=download&amp;shareKey=eafff8cb4d4bbb874ca08af10d2c90dd" alt="image4"> 在你想插入图片的地方</p><pre><code class="hljs">![image](复制的图片链接)</code></pre><p>然后你就会发现显示成功！</p>]]></content>
    
    
    <categories>
      
      <category>问题解决</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>解决pip下载速度慢的问题</title>
    <link href="/2021/04/04/%E8%A7%A3%E5%86%B3pip%E4%B8%8B%E8%BD%BD%E9%80%9F%E5%BA%A6%E6%85%A2%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <url>/2021/04/04/%E8%A7%A3%E5%86%B3pip%E4%B8%8B%E8%BD%BD%E9%80%9F%E5%BA%A6%E6%85%A2%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p>pip有时下载库很慢，半天下不下来我也挺烦，就在网上看到这个方法，一用，很可以呀！记录一下：<span id="more"></span> ### 1.临时 pip install -ihttps://pypi.tuna.tsinghua.edu.cn/simple some-package ### 2设为默认 pipinstall pip -U pip config set global.index-urlhttps://pypi.tuna.tsinghua.edu.cn/simple</p><p>一用，确实快了很多，不可同日而语，嘿嘿</p><p>镜像源的话我觉得两个都行，一个是上面的，还有一个:http://pypi.douban.com/simple/</p><p>以上部分内容参考自：https://blog.csdn.net/qq_39123009/article/details/88088134?utm_source=app&amp;app_version=4.5.2</p>]]></content>
    
    
    <categories>
      
      <category>问题解决</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
